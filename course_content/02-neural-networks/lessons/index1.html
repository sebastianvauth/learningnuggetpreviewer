<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome to the World of Neural Networks! A Brief History</title>
  <style>
      body {
          font-family: Arial, sans-serif;
          max-width: 800px;
          margin: 0 auto;
          padding: 20px;
          background-color: #ffffff;
          font-size: 150%;
      }
      section {
          margin-bottom: 20px;
          padding: 20px;
          background-color: #ffffff;
          display: none;
          opacity: 0;
          transition: opacity 0.5s ease-in;
      }
      h1, h2, h3, h4 {
          color: #333;
          margin-top: 20px;
      }
      p, li {
          line-height: 1.6;
          color: #444;
          margin-bottom: 20px;
      }
      ul {
          padding-left: 20px;
      }
      .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          text-align: left;
      }
      .image-placeholder img, .interactive-placeholder img {
          max-width: 100%;
          height: auto;
          border-radius: 5px;
      }
      .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          padding: 20px;
          border-radius: 8px;
          margin-top: 20px;
      }
      .vocab-section {
          background-color: #f0f8ff;
      }
      .vocab-section h3 {
          color: #1e90ff;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .vocab-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .vocab-term {
          font-weight: bold;
          color: #1e90ff;
      }
      .why-it-matters {
          background-color: #ffe6f0;
      }
      .why-it-matters h3 {
          color: #d81b60;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .stop-and-think {
          background-color: #e6e6ff;
      }
      .stop-and-think h3 {
          color: #4b0082;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .continue-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #007bff;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .reveal-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #4b0082;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .test-your-knowledge {
          background-color: #e6ffe6; /* Light green background */
      }
      .test-your-knowledge h3 {
          color: #28a745; /* Dark green heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .test-your-knowledge h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .test-your-knowledge p {
          margin-bottom: 15px;
      }
      .check-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #28a745; /* Green background */
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
          border: none;
          font-size: 1em;
      }
      .option-container {
          margin-bottom: 10px;
      }
      .option-label {
          display: block;
          margin-bottom: 5px;
          cursor: pointer;
      }
      .option-feedback {
          display: none;
          margin-left: 25px;
          padding: 5px;
          border-radius: 5px;
      }
      .correct-feedback {
          background-color: #d4edda;
          color: #155724;
      }
      .incorrect-feedback {
          background-color: #f8d7da;
          color: #721c24;
      }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <section id="section1">
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A stylized image of a retro-futuristic brain with glowing circuits, perhaps with a 'Loading History...' progress bar underneath, to set a techy, exploratory tone.">
      </div>
      <h1>Welcome to the World of Neural Networks! A Brief History</h1>
      <p>Hey there, and welcome to our journey into the amazing world of Neural Networks! Ever wondered how your phone magically recognizes your face, or how apps can translate languages in a snap, or even how computers can master super complex games like Go? A huge part of the answer lies in something called <strong>Neural Networks</strong>.</p>
      <p>Think of them as computer systems inspired by the intricate network of neurons in our own brains. Cool, right?</p>
      <p>In this very first lesson, we're going to hop into our time machine and take a quick but exciting trip back to see how these incredible ideas first sparked and evolved. It's not just about memorizing dates; understanding this journey will help us truly appreciate the power of what we have today and get a glimpse of where this incredible field might be heading. Ready to explore the milestones that shaped the AI we see all around us? Let's go!</p>
      <div class="continue-button" onclick="showNextSection(2)">Continue</div>
  </section>

  <section id="section2">
      <h2>The Timeline of Brainy Ideas</h2>
      <p>Our story isn't a single 'aha!' moment, but a series of brilliant sparks over decades. Let's walk through some of the most important milestones that built the foundations for today's AI.</p>
      <div class="interactive-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A dynamic, horizontal timeline graphic. Key years (1943, 1957, 1965, 1970, 1979, 1982, 1986, 1997, 2006-2012, 2012, 2016) appear sequentially along the timeline. When a year appears, a short description of the milestone and a relevant small icon (e.g., a single glowing neuron for TLU, interconnected nodes for multilayer network, an eye for AlexNet, a Go board for AlphaGo) animates next to it.">
      </div>
      <p>Let's zoom in on a few of these pivotal moments:</p>
      <div class="continue-button" onclick="showNextSection(3)">Continue</div>
  </section>

  <section id="section3">
      <h3>1943: The Very First Spark!</h3>
      <p>Our journey begins with the "Threshold Logic Unit" or TLU. Imagine two scientists, McCulloch and Pitts, sketching out the first super-simple mathematical model of how a brain cell might work. It was basic, but it was the conceptual seed!</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A black and white, vintage-style photo or illustration of two scientists (representing McCulloch and Pitts) looking thoughtfully at a chalkboard with a very simple diagram of a TLU (a circle with inputs and one output).">
      </div>
      <div class="continue-button" onclick="showNextSection(4)">Continue</div>
  </section>

  <section id="section4">
      <h3>1957: Enter the Perceptron!</h3>
      <p>Fast forward a bit, and Frank Rosenblatt introduces the Perceptron. This wasn't just an idea; it was a real, (for the time) functioning model that could <em>learn</em> from data to make simple classifications. Think of it as the first trainable artificial neuron. It caused a lot of excitement!</p>
      <div class="vocab-section">
          <h3>Build Your Vocab</h3>
          <h4 class="vocab-term">Perceptron</h4>
          <p>An algorithm for supervised learning of binary classifiers. It's an early type of artificial neuron, a linear classifier that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.</p>
      </div>
      <div class="continue-button" onclick="showNextSection(5)">Continue</div>
  </section>

  <section id="section5">
      <h3>The Middle Ages & The Algorithm</h3>
      <p>Through the 60s, 70s, and 80s, progress continued. We saw the first working <em>multilayer</em> networks (networks with layers of neurons, not just one!), which was a big step. And critically, the <strong>Backpropagation algorithm</strong> was developed (though its full power for neural nets wasn't immediately obvious to everyone). This algorithm is the secret sauce that lets complex, multi-layered networks actually learn efficiently. We'll talk <em>a lot</em> more about this later, it's super important!</p>
      <div class="stop-and-think">
          <h3>Stop and Think</h3>
          <h4>Why do you think going from a single Perceptron to <em>multilayer</em> networks was such a big deal? What kind of problems might multiple layers help solve that a single layer couldn't?</h4>
          <button class="reveal-button" onclick="revealAnswer('stop-and-think-1')">Reveal</button>
          <p id="stop-and-think-1" style="display: none;">Single perceptrons can only solve linearly separable problems (we'll see this later!). Multi-layer networks, with the help of non-linear activation functions (another future topic!), can learn much more complex, non-linear relationships in data. Think of it as going from drawing a straight line to drawing complex curves to separate categories!</p>
      </div>
      <div class="continue-button" onclick="showNextSection(6)">Continue</div>
  </section>

  <section id="section6">
      <h3>Specialized Brains & Memory Boosts</h3>
      <p>The late 70s and 80s also brought us the first ideas for <strong>Convolutional Neural Networks (CNNs)</strong>, which are now superstars for image recognition, and <strong>Recurrent Neural Networks (RNNs)</strong>, designed for handling sequences like text or speech. Then, in <strong>1997</strong>, a huge breakthrough for RNNs: <strong>Long Short-Term Memory (LSTM)</strong> networks were developed by Hochreiter and Schmidhuber. These gave RNNs a much better 'memory,' allowing them to learn from longer sequences of data.</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A split image: one side showing a stylized eye with a grid overlay (representing CNNs and vision), the other side showing sound waves or text flowing in a loop (representing RNNs/LSTMs and sequences).">
      </div>
      <div class="continue-button" onclick="showNextSection(7)">Continue</div>
  </section>

  <section id="section7">
      <h3>The Deep Learning Explosion (2006-2012 and beyond!)</h3>
      <p>This is where things <em>really</em> took off and the term 'Deep Learning' (referring to networks with many, many layers) became mainstream. Why then? A perfect storm of more powerful computers (especially GPUs!), vast amounts of available data (thank you, internet!), and refined algorithms.</p>
      <div class="why-it-matters">
          <h3>Why It Matters</h3>
          <p>Understanding these historical milestones isn't just for trivia! It shows us how ideas build upon each other. The challenges faced by early researchers (like training deep networks or handling long sequences) led to the breakthroughs that power today's AI. It's a story of persistence and innovation.</p>
      </div>
      <div class="continue-button" onclick="showNextSection(8)">Continue</div>
  </section>

  <section id="section8">
      <h3>Landmark Events</h3>
      <p>Two landmark events really showcased this new power:</p>
      <ol>
          <li><strong>2012: AlexNet Wins Big!</strong> A deep convolutional neural network called AlexNet blew the competition out of the water in the ImageNet challenge (a massive image recognition contest). This was a wake-up call to the world about the power of deep learning for vision.</li>
          <li><strong>2016: AlphaGo Conquers Go!</strong> Google DeepMind's AlphaGo, using deep neural networks and reinforcement learning, defeated the world champion at Go, a game considered vastly more complex than chess. This was another 'Sputnik moment' for AI.</li>
      </ol>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A montage: a photo of the AlexNet architecture diagram, and a photo of Lee Sedol (Go champion) playing against the AlphaGo program, with a 'VICTORY!' stamp over the AlphaGo side.">
      </div>
      <div class="continue-button" onclick="showNextSection(9)">Continue</div>
  </section>

  <section id="section9">
      <h2>Why History Matters & What's Next?</h2>
      <p>So, from simple concepts of artificial brain cells to AI systems that can outperform humans on specific complex tasks, it's been quite a ride!</p>
      <p>This historical journey shows us a few key things:</p>
      <ol>
          <li><strong>Ideas Evolve:</strong> Concepts like the neuron were just the start. Layering them, finding ways to train them (backpropagation!), and specializing them (CNNs, RNNs) were all crucial steps.</li>
          <li><strong>Enabling Factors:</strong> Progress isn't just about ideas; it also needs the right environment â€“ more data and more computing power were critical for the deep learning boom.</li>
          <li><strong>Impact:</strong> These advancements aren't just academic; they lead to real-world applications that affect our daily lives.</li>
      </ol>
      <div class="test-your-knowledge">
          <h3>Test Your Knowledge</h3>
          <h4>Which of these was NOT a key factor directly mentioned as contributing to the 'Deep Learning Explosion' around 2006-2012?</h4>
          <div class="option-container">
              <label class="option-label">
                  <input type="radio" name="quiz" value="option1" onclick="checkAnswer(this, false)"> More powerful computers (GPUs)
              </label>
              <div id="feedback1" class="option-feedback incorrect-feedback">This was mentioned as a key enabling factor!</div>
          </div>
          <div class="option-container">
              <label class="option-label">
                  <input type="radio" name="quiz" value="option2" onclick="checkAnswer(this, false)"> Vast amounts of available data
              </label>
              <div id="feedback2" class="option-feedback incorrect-feedback">This was also mentioned as crucial fuel for deep learning models.</div>
          </div>
          <div class="option-container">
              <label class="option-label">
                  <input type="radio" name="quiz" value="option3" onclick="checkAnswer(this, true)"> The invention of the internet itself
              </label>
              <div id="feedback3" class="option-feedback correct-feedback">Correct! While the internet <em>led</em> to vast amounts of data, its invention happened much earlier. The <em>availability</em> of this data for training was key during the deep learning boom.</div>
          </div>
          <div class="option-container">
              <label class="option-label">
                  <input type="radio" name="quiz" value="option4" onclick="checkAnswer(this, false)"> Refined algorithms (like better ways to train deep networks)
              </label>
              <div id="feedback4" class="option-feedback incorrect-feedback">Improvements in algorithms and understanding were indeed part of the progress.</div>
          </div>
      </div>
      <div class="continue-button" onclick="showNextSection(10)">Continue</div>
  </section>

  <section id="section10">
      <h2>Looking Ahead</h2>
      <p>This historical backdrop sets the stage for everything else we're going to learn. We've seen <em>that</em> neural networks became powerful, but <em>why</em> did having many layers ('deep' learning) and lots of data make such a difference?</p>
      <p>In our next lesson, we'll explore exactly that: the relationship between data, the complexity of these networks, and their incredible performance. Get ready to see why 'data is the new oil' is an especially true saying in the world of AI!</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A friendly, futuristic robot character waving goodbye, with a thought bubble showing a graph with an upward trend, hinting at future learning and progress.">
      </div>
  </section>

  <script>
      // Show the first section initially
      document.getElementById("section1").style.display = "block";
      document.getElementById("section1").style.opacity = "1";

      function showNextSection(nextSectionId) {
          const currentButton = event.target;
          const nextSection = document.getElementById("section" + nextSectionId);
          
          currentButton.style.display = "none";
          
          nextSection.style.display = "block";
          setTimeout(() => {
              nextSection.style.opacity = "1";
          }, 10);

          setTimeout(() => {
              nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }, 500);
      }

      function revealAnswer(id) {
          const revealText = document.getElementById(id);
          const revealButton = event.target;
          
          revealText.style.display = "block";
          revealButton.style.display = "none";
      }

      function checkAnswer(radio, isCorrect) {
          // Get the feedback element associated with this option
          const feedbackId = "feedback" + radio.value.replace("option", "");
          const feedbackElement = document.getElementById(feedbackId);
          
          // Show the feedback
          feedbackElement.style.display = "block";
          
          // Disable all radio buttons after an answer is selected
          const radioButtons = document.querySelectorAll('input[name="quiz"]');
          radioButtons.forEach(button => {
              button.disabled = true;
          });
      }
  </script>
</body>
</html>