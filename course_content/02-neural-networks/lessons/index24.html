<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Universal Approximation in Action: Examples & Reflections</title>
  <style>
      body {
          font-family: Arial, sans-serif;
          max-width: 800px;
          margin: 0 auto;
          padding: 20px;
          background-color: #ffffff;
          font-size: 150%;
      }
      section {
          margin-bottom: 20px;
          padding: 20px;
          background-color: #ffffff;
          display: none;
          opacity: 0;
          transition: opacity 0.5s ease-in;
      }
      h1, h2, h3, h4 {
          color: #333;
          margin-top: 20px;
      }
      p, li {
          line-height: 1.6;
          color: #444;
          margin-bottom: 20px;
      }
      ul {
          padding-left: 20px;
      }
      .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          text-align: left;
      }
      .image-placeholder img, .interactive-placeholder img {
          max-width: 100%;
          height: auto;
          border-radius: 5px;
      }
      .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          padding: 20px;
          border-radius: 8px;
          margin-top: 20px;
      }
      .vocab-section {
          background-color: #f0f8ff;
      }
      .vocab-section h3 {
          color: #1e90ff;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .vocab-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .vocab-term {
          font-weight: bold;
          color: #1e90ff;
      }
      .why-it-matters {
          background-color: #ffe6f0;
      }
      .why-it-matters h3 {
          color: #d81b60;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .stop-and-think {
          background-color: #e6e6ff;
      }
      .stop-and-think h3 {
          color: #4b0082;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .continue-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #007bff;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .reveal-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #4b0082;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .test-your-knowledge {
          background-color: #e6ffe6; /* Light green background */
      }
      .test-your-knowledge h3 {
          color: #28a745; /* Dark green heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .test-your-knowledge h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .test-your-knowledge p {
          margin-bottom: 15px;
      }
      .check-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #28a745; /* Green background */
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
          border: none;
          font-size: 1em;
      }

      .faq-section {
          background-color: #fffbea; /* Light yellow background */
      }
      .faq-section h3 {
          color: #ffcc00; /* Bright yellow heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .faq-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      blockquote {
          border-left: 4px solid #ccc;
          margin-left: 0;
          padding-left: 16px;
          font-style: italic;
      }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <section id="section1">
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="An image of a scientist in a lab coat, holding up a beaker with a glowing, perfectly formed function graph inside it, while a neural network diagram hums contentedly in the background. Caption: 'Experiment Successful!'">
      </div>
      <h1>Lesson 24: Universal Approximation in Action: Examples & Reflections</h1>
      <h2>From Theory to Tangible Results</h2>
      <p>Hey aspiring modelers! We've journeyed through the powerful theory of the Universal Approximation Theorem (UAT), understanding that neural networks (even simple ones, if complex enough) can theoretically approximate any continuous function. We also discussed how this relates to the ideal 'Optimal Bayes-Hypothesis' and the practical challenges of underfitting and overfitting.</p>
      <p>Now, it's time to get our hands dirty (figuratively!) and see these concepts <strong>in action</strong>! We're going to look at some visual examples of how changing the complexity of a neural network – specifically, the number of neurons in its single hidden layer – affects its ability to learn patterns in both <strong>regression</strong> and <strong>classification</strong> tasks. Let's see what happens when theory meets data! (This lesson visualizes the concepts from Slides 50-55 and reflects with quotes from Slide 56).</p>
      <div class="continue-button" onclick="showNextSection(2)">Continue</div>
  </section>

  <section id="section2">
      <h2>Experiment 1: Regression - Fitting a Wiggly Curve</h2>
      <p>Our first experiment involves a <strong>regression task</strong>. Imagine we have some data points that seem to follow a kind of wiggly, sine-wave-like pattern, but with some noise. Our goal is to train a neural network with <strong>one hidden layer</strong> (using Sigmoid activation) to learn and approximate this underlying curve. We'll vary the number of neurons in that hidden layer and see what happens. (Referencing setup from Slide 50).</p>
      
      <p><strong>Experiment Setup (Regression):</strong></p>
      <ul>
          <li>Training samples: 40, Test samples: 40</li>
          <li>Network: 1 input, 1 hidden layer (Sigmoid activation), 1 output (Identity activation)</li>
          <li>Hidden layer sizes to test: 1, 2, 5, 10, 100 neurons</li>
          <li>Training: 6000 iterations.</li>
      </ul>
      
      <div class="interactive-placeholder">
          <img src="/placeholder.svg?height=400&width=600" alt="A 'Regression Model Explorer' widget showing a scatter plot with noisy training data points and a slider to select the number of hidden neurons, displaying the resulting fit curve and error metrics.">
      </div>
      
      <p><strong>Observations from the Regression Experiment:</strong></p>
      <ul>
          <li><strong>Too Few Neurons (e.g., N=1, N=2):</strong> The network is too simple (low capacity). It can't capture the complex shape of the data. This is <strong>underfitting</strong>. Both training and test errors are high.</li>
          <li><strong>A Good Number of Neurons (e.g., N=5):</strong> The network has enough capacity to learn the underlying pattern without fitting the noise too much. Both training and test errors are low. This is a good balance – the model <strong>generalizes</strong> well.</li>
          <li><strong>Too Many Neurons (e.g., N=100):</strong> The network becomes <em>too</em> flexible. It starts to memorize the training data, including its random noise, instead of just the underlying trend. The training error becomes very low, but the test error shoots up! This is <strong>overfitting</strong>.</li>
      </ul>
      
      <p>This clearly shows the UAT in action – as we add neurons, the network <em>can</em> fit more complex shapes. But it also shows the practical challenge of finding the right capacity to avoid both underfitting and overfitting.</p>
      
      <div class="continue-button" onclick="showNextSection(3)">Continue</div>
  </section>

  <section id="section3">
      <h2>Experiment 2: Classification - Separating Complex Classes</h2>
      <p>Now let's try a <strong>classification task</strong>. Imagine we have data points belonging to two classes (say, purple and yellow) that are arranged in a tricky, non-linear pattern, like two intertwined spirals or circles. Our goal is to train a neural network (again, one hidden layer with Sigmoid) to learn a decision boundary that separates these classes. (Referencing setup from Slide 53).</p>
      
      <p><strong>Experiment Setup (Classification):</strong></p>
      <ul>
          <li>Training samples: 250, Test samples: 250</li>
          <li>Network: 2 inputs, 1 hidden layer (Sigmoid activation), 1 output (Sigmoid activation for binary class)</li>
          <li>Hidden layer sizes to test: 1, 2, 5, 10, 50 neurons</li>
          <li>Training: 6000 iterations.</li>
      </ul>
      
      <div class="interactive-placeholder">
          <img src="/placeholder.svg?height=400&width=600" alt="A 'Classification Model Explorer' widget showing a 2D scatter plot with purple and yellow data points in a complex pattern, and a slider to select the number of hidden neurons, displaying the resulting decision boundary and accuracy metrics.">
      </div>
      
      <p><strong>Observations from the Classification Experiment:</strong></p>
      <ul>
          <li><strong>Too Few Neurons (e.g., N=1, N=2):</strong> The network can only create very simple (linear or slightly bent) decision boundaries. It <strong>underfits</strong> because it doesn't have the capacity to model the complex separation needed.</li>
          <li><strong>More Neurons (e.g., N=10, N=50):</strong> As we increase the number of hidden neurons, the network becomes capable of learning much more intricate, non-linear decision boundaries. It can better separate the intertwined classes.
              <ul>
                  <li>With N=10, it finds a good, general boundary.</li>
                  <li>With N=50, it learns an extremely precise boundary. In this particular example from the slides, even with 50 neurons, the test accuracy remained very high (0.997), suggesting that the underlying pattern was learnable without much noise causing overfitting. In real-world scenarios with noisier data, N=50 might well have started to overfit, creating overly complex wiggles to catch every training point, which wouldn't generalize as well.</li>
              </ul>
          </li>
      </ul>
      
      <div class="vocab-section">
          <h3>Build Your Vocab</h3>
          <h4 class="vocab-term">Decision Boundary</h4>
          <p>In classification, a decision boundary is a hypersurface (a line in 2D, a surface in 3D, etc.) that partitions the underlying vector space into two or more sets, one for each class. The classifier assigns a class to a point based on which side of the decision boundary it falls.</p>
      </div>
      
      <div class="continue-button" onclick="showNextSection(4)">Continue</div>
  </section>

  <section id="section4">
      <h2>Reflections: The Wisdom of the Gurus (Slide 56)</h2>
      <p>These examples beautifully illustrate the power and the practical considerations of the Universal Approximation Theorem. Let's reflect on this with some insightful quotes from pioneers in the field.</p>
      
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A split image with two thought bubbles. Left bubble: Ian Goodfellow's quote, with a visual of a single, very wide, and slightly unwieldy hidden layer that looks like it might be struggling to generalize. Right bubble: Elon Musk's quote, with a visual of a φ (activation function) symbol acting like a key unlocking a complex pattern.">
      </div>
      
      <p>1. <strong>Ian Goodfellow (a leading Deep Learning researcher):</strong></p>
      <blockquote>
          <p><em>"A feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly."</em></p>
      </blockquote>
      
      <p>This perfectly captures what we saw. Yes, a single layer <em>can</em> do it (UAT), but:</p>
      <ul>
          <li>'Infeasibly large': For very complex functions, you might need an astronomical number of neurons, making it impractical.</li>
          <li>'Fail to learn and generalize correctly': Even if it <em>can</em> represent the function, training it effectively (finding the right weights from data) and ensuring it generalizes to new data (doesn't just overfit) are separate, major challenges.</li>
      </ul>
      
      <p>2. <strong>Elon Musk (Entrepreneur with significant AI ventures):</strong></p>
      <blockquote>
          <p><em>"Introducing non-linearity via an activation function allows us to approximate any function. It's quite simple, really."</em></p>
      </blockquote>
      
      <p>This quote emphasizes the fundamental role of those <strong>non-linear activation functions</strong> ($$\phi$$). Without them, as we learned, even a deep network would just be linear. It's the non-linearity at each neuron that gives the network its incredible power to bend and shape its internal representations to approximate complex functions.</p>
      
      <div class="why-it-matters">
          <h3>Why It Matters</h3>
          <p>The UAT provides the theoretical 'can do' for neural networks. These expert reflections remind us of the 'how to do it well in practice' and 'what are the key ingredients'. It's a blend of theoretical possibility and practical engineering to build effective models.</p>
      </div>
      
      <div class="continue-button" onclick="showNextSection(5)">Continue</div>
  </section>

  <section id="section5">
      <h2>Course Recap & What We've Learned</h2>
      <p>And with that, we've reached a major milestone in our journey!</p>
      
      <p>Let's take a moment to reflect on what we've covered in this foundational part of our course:</p>
      
      <ul>
          <li><strong>The Big Picture:</strong> We started with the history of neural networks and saw how data fuels their performance, leading to revolutions like in ImageNet.</li>
          <li><strong>The Building Blocks:</strong> We dissected the biological neuron for inspiration, then built its mathematical counterpart, the artificial neuron, understanding inputs, weights, bias, and the crucial two-step calculation (net input $$z$$ and activation $$a = \phi(z)$$).</li>
          <li><strong>Weaving the Web:</strong> We learned how neurons are organized into input, hidden, and output layers to form feedforward, often fully connected, networks.</li>
          <li><strong>Tools & Notation:</strong> We got a glimpse of powerful Deep Learning Frameworks and then mastered matrix notation for concisely representing layer-wise computations.</li>
          <li><strong>The Spark of Non-Linearity:</strong> We toured the 'Activation Function Zoo', understanding why non-linearity is key, and met Identity, Sigmoid, Tanh, ReLU, Leaky ReLU, and learned about their properties and derivatives.</li>
          <li><strong>Handling Multiple Choices:</strong> We saw how to structure output layers for multiclass classification and how the Softmax function turns raw scores into probabilities.</li>
          <li><strong>Logic & Limits:</strong> We explored how simple neurons can model basic logic (AND/OR) due to linear separability, and why the non-linearly separable XOR problem requires a hidden layer, which learns to transform the data into a more useful representation.</li>
          <li><strong>Measuring Success:</strong> We defined Loss Functions (for single samples) and Cost Functions (average error over the dataset) for both regression (L2 Loss/MSE) and classification (Cross-Entropy).</li>
          <li><strong>The Power Within:</strong> Finally, we unpacked the Universal Approximation Theorem, understanding its profound implications for the expressive power of neural networks, and its connection to practical issues like underfitting, overfitting, and the preference for deep architectures.</li>
      </ul>
      
      <p>That's a huge amount of ground covered!</p>
      
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A vibrant montage or a 'diploma' graphic showcasing icons for all the major topics covered: a historical scroll, a data graph, a neuron, network layers, matrices, activation function graphs, logic gates, a loss graph, and the UAT symbol.">
      </div>
      
      <div class="continue-button" onclick="showNextSection(6)">Continue</div>
  </section>

  <section id="section6">
      <h2>Where Do We Go From Here?</h2>
      <p>You now have a very solid foundation in the core concepts of neural networks!</p>
      
      <p>This knowledge is the bedrock for understanding more advanced topics, such as:</p>
      
      <ul>
          <li><strong>How do networks actually <em>learn</em> those weights and biases?</strong> (This involves understanding Gradient Descent and the Backpropagation algorithm).</li>
          <li><strong>Specialized Architectures:</strong> Convolutional Neural Networks (CNNs) for images, Recurrent Neural Networks (RNNs) and Transformers for sequences (like text and time series).</li>
          <li><strong>Training Techniques:</strong> How to effectively train deep networks, deal with overfitting (regularization), optimize hyperparameters, and more.</li>
          <li><strong>Countless Applications:</strong> Applying these powerful tools to solve real-world problems in various domains.</li>
      </ul>
      
      <p>This course was designed to give you the 'why' and the 'what'. The next steps in your learning journey will often focus on the 'how'.</p>
      
      <p>Thank you for joining this foundational exploration. Keep that curiosity alive, and happy learning as you continue to delve deeper into the fascinating and rapidly evolving world of Artificial Intelligence and Deep Learning!</p>
      
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A character standing at a crossroads. One path behind them is labeled 'Foundations Covered!'. Several paths ahead are labeled 'Backpropagation', 'CNNs', 'RNNs', 'Transformers', 'Advanced Training'. The character looks excited and ready to explore.">
      </div>
  </section>

  <script>
      // Show the first section initially
      document.getElementById("section1").style.display = "block";
      document.getElementById("section1").style.opacity = "1";

      function showNextSection(nextSectionId) {
          const currentButton = event.target;
          const nextSection = document.getElementById("section" + nextSectionId);
          
          currentButton.style.display = "none";
          
          nextSection.style.display = "block";
          setTimeout(() => {
              nextSection.style.opacity = "1";
          }, 10);

          setTimeout(() => {
              nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }, 500);
      }

      function revealAnswer(id) {
          const revealText = document.getElementById(id);
          const revealButton = event.target;
          
          revealText.style.display = "block";
          revealButton.style.display = "none";
      }
  </script>
</body>
</html>