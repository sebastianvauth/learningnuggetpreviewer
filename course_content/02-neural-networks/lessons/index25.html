<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Exercise Lesson 5.1: Neuron Calculations</title>
  <style>
      body {
          font-family: Arial, sans-serif;
          max-width: 800px;
          margin: 0 auto;
          padding: 20px;
          background-color: #ffffff;
          font-size: 150%;
      }
      section {
          margin-bottom: 20px;
          padding: 20px;
          background-color: #ffffff;
          display: none;
          opacity: 0;
          transition: opacity 0.5s ease-in;
      }
      h1, h2, h3, h4 {
          color: #333;
          margin-top: 20px;
      }
      p, li {
          line-height: 1.6;
          color: #444;
          margin-bottom: 20px;
      }
      ul {
          padding-left: 20px;
      }
      .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          text-align: left;
      }
      .image-placeholder img, .interactive-placeholder img {
          max-width: 100%;
          height: auto;
          border-radius: 5px;
      }
      .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think, .math-explainer {
          padding: 20px;
          border-radius: 8px;
          margin-top: 20px;
      }
      .vocab-section {
          background-color: #f0f8ff;
      }
      .vocab-section h3 {
          color: #1e90ff;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .vocab-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .vocab-term {
          font-weight: bold;
          color: #1e90ff;
      }
      .why-it-matters {
          background-color: #ffe6f0;
      }
      .why-it-matters h3 {
          color: #d81b60;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .stop-and-think {
          background-color: #e6e6ff;
      }
      .stop-and-think h3 {
          color: #4b0082;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .continue-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #007bff;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .reveal-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #4b0082;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .test-your-knowledge {
          background-color: #e6ffe6; /* Light green background */
      }
      .test-your-knowledge h3 {
          color: #28a745; /* Dark green heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .test-your-knowledge h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .test-your-knowledge p {
          margin-bottom: 15px;
      }
      .check-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #28a745; /* Green background */
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
          border: none;
          font-size: 1em;
      }
      .faq-section {
          background-color: #fffbea; /* Light yellow background */
      }
      .faq-section h3 {
          color: #ffcc00; /* Bright yellow heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .faq-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .math-explainer {
          background-color: #f5f5f5;
          border-left: 4px solid #007bff;
      }
      .math-explainer h3 {
          color: #007bff;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .math-step {
          margin-bottom: 15px;
      }
      .exercise-problem {
          background-color: #f9f9f9;
          padding: 15px;
          border-radius: 8px;
          margin-bottom: 20px;
          border-left: 4px solid #28a745;
      }
      .problem-statement {
          margin-bottom: 15px;
      }
      .answer-field {
          margin-bottom: 10px;
      }
      .answer-field label {
          display: inline-block;
          width: 200px;
          font-weight: bold;
      }
      .answer-field input {
          padding: 8px;
          border-radius: 4px;
          border: 1px solid #ccc;
          width: 100px;
      }
      .feedback {
          margin-top: 10px;
          padding: 10px;
          border-radius: 4px;
          display: none;
      }
      .correct {
          background-color: #d4edda;
          color: #155724;
      }
      .incorrect {
          background-color: #f8d7da;
          color: #721c24;
      }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <section id="section1">
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A friendly cartoon neuron character wearing a sweatband and flexing its 'axon' bicep, with math symbols floating around. Caption: 'Time for a Workout!'">
      </div>
      <h1>Exercise Lesson 5.1: Neuron Calculations - Let's Get Practical!</h1>
      <p>Hey there, future neural network architects! In our last conceptual lesson (Lesson 5), we did a deep dive into the <strong>artificial neuron</strong>. We met its components – inputs, weights, bias – and learned about its crucial two-step calculation dance: first, the <strong>net input $$z$$</strong> (the weighted sum plus bias), and then the <strong>activation $$a$$</strong> (passing $$z$$ through an activation function $$\phi$$).</p>
      <p>Theory is fantastic, but there's nothing like getting your hands dirty with some numbers to really make it click. So, in this exercise lesson, we're going to do just that! We'll work through a few examples, calculating $$z$$ and $$a$$ for different scenarios. This will help solidify your understanding of how a single neuron processes information. Ready to crunch some numbers? Let's go!</p>
      <div class="continue-button" onclick="showNextSection(2)">Continue</div>
  </section>

  <section id="section2">
      <h2>Refresher: The Neuron's Math</h2>
      <p>Before we jump into the problems, let's quickly refresh our memory on the core formulas for a single neuron:</p>
      <div class="math-explainer">
          <h3>Neuron Calculation Recap</h3>
          <div class="math-step">
              <h4>1. Net Input $$z$$ (Weighted Sum + Bias)</h4>
              <p>If a neuron has $$m$$ inputs $$x_1, x_2, ..., x_m$$, with corresponding weights $$w_1, w_2, ..., w_m$$, and a bias $$b$$, the net input $$z$$ is:</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + \dots + (w_m x_m) + b = \left( \sum_{i=1}^{m} w_i x_i \right) + b \]</p>
          </div>
          <div class="math-step">
              <h4>2. Activation $$a$$ (Output)</h4>
              <p>The net input $$z$$ is then passed through an activation function $$\phi$$ to produce the neuron's final output $$a$$:</p>
              <p>\[ a = \phi(z) \]</p>
          </div>
      </div>
      <p>Keep these two steps in mind as we tackle the exercises!</p>
      <div class="continue-button" onclick="showNextSection(3)">Continue</div>
  </section>

  <section id="section3">
      <h2>Difficulty 1: Easy Peasy Step Activation</h2>
      <p>Let's start with a straightforward scenario. For these first problems, we'll use a very simple <strong>Step Activation Function</strong>:</p>
      <p>If $$z \geq 0$$, then $$a = 1$$<br>
      If $$z < 0$$, then $$a = 0$$</p>
      <p>This means the neuron 'fires' (outputs 1) if its net input is zero or positive, and stays 'off' (outputs 0) if its net input is negative.</p>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 1:</strong> A neuron has two inputs, $$x_1$$ and $$x_2$$.<br>
              Given:<br>
              - Input 1: $$x_1 = 1$$<br>
              - Input 2: $$x_2 = 0$$<br>
              - Weight for x1: $$w_1 = 0.5$$<br>
              - Weight for x2: $$w_2 = -1.0$$<br>
              - Bias: $$b = 0.2$$</p>
              <p>Calculate the net input $$z$$ and the activation $$a$$ using the Step Activation Function.</p>
          </div>
          <div class="answer-field">
              <label for="z_1">Net Input z:</label>
              <input type="number" id="z_1" step="0.1">
          </div>
          <div class="answer-field">
              <label for="a_1">Activation a:</label>
              <input type="number" id="a_1" step="1">
          </div>
          <button class="check-button" onclick="checkAnswer('problem1', ['z_1', 'a_1'], [0.7, 1])">Check Answer</button>
          <div id="feedback-problem1" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem1')">Show Solution</button>
          <div id="solution-problem1" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Calculate the net input $$z$$:</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + b \]</p>
              <p>Substitute the values:</p>
              <p>\[ z = (0.5 \times 1) + (-1.0 \times 0) + 0.2 \]</p>
              <p>Perform the multiplication:</p>
              <p>\[ z = 0.5 + 0 + 0.2 \]</p>
              <p>Calculate the sum:</p>
              <p>\[ z = 0.7 \]</p>
              <p>2. Apply the Step Activation Function $$a = \phi(z)$$:</p>
              <p>Since $$z = 0.7$$, which is $$\geq 0$$...</p>
              <p>\[ a = 1 \]</p>
              <p><strong>Final Answer:</strong> $$z = 0.7$$, $$a = 1$$</p>
          </div>
      </div>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 2:</strong> Same neuron, same Step Activation Function, but new inputs and bias!<br>
              Given:<br>
              - Input 1: $$x_1 = -2$$<br>
              - Input 2: $$x_2 = 1$$<br>
              - Weight for x1: $$w_1 = 0.8$$<br>
              - Weight for x2: $$w_2 = 1.0$$<br>
              - Bias: $$b = 0.5$$</p>
              <p>Calculate $$z$$ and $$a$$.</p>
          </div>
          <div class="answer-field">
              <label for="z_2">Net Input z:</label>
              <input type="number" id="z_2" step="0.1">
          </div>
          <div class="answer-field">
              <label for="a_2">Activation a:</label>
              <input type="number" id="a_2" step="1">
          </div>
          <button class="check-button" onclick="checkAnswer('problem2', ['z_2', 'a_2'], [-0.1, 0])">Check Answer</button>
          <div id="feedback-problem2" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem2')">Show Solution</button>
          <div id="solution-problem2" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Calculate $$z$$:</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + b \]</p>
              <p>Substitute:</p>
              <p>\[ z = (0.8 \times -2) + (1.0 \times 1) + 0.5 \]</p>
              <p>Multiply:</p>
              <p>\[ z = -1.6 + 1.0 + 0.5 \]</p>
              <p>Sum:</p>
              <p>\[ z = -0.1 \]</p>
              <p>2. Apply Step Activation $$a = \phi(z)$$:</p>
              <p>Since $$z = -0.1$$, which is $$< 0$$...</p>
              <p>\[ a = 0 \]</p>
              <p><strong>Final Answer:</strong> $$z = -0.1$$, $$a = 0$$</p>
          </div>
      </div>
      
      <p>How did you do? The step function makes the final activation pretty clear-cut once you have $$z$$!</p>
      <div class="continue-button" onclick="showNextSection(4)">Continue</div>
  </section>

  <section id="section4">
      <h2>Difficulty 2: Engaging with Sigmoid</h2>
      <p>Alright, let's level up! For these next problems, our neuron will use the <strong>Sigmoid Activation Function</strong>:</p>
      <p>\[ \phi(z) = \frac{1}{1 + e^{-z}} \]</p>
      <p>Remember, this function squashes its output to be between 0 and 1. To help you out, here are a few pre-calculated $$e^{-z}$$ values you might need (or you can use a calculator if you have one that does $$e^x$$):</p>
      <ul>
          <li>$$e^{-0} = 1$$</li>
          <li>$$e^{-1} \approx 0.368$$</li>
          <li>$$e^{1} \approx 2.718$$</li>
          <li>$$e^{-2} \approx 0.135$$</li>
          <li>$$e^{2} \approx 7.389$$</li>
          <li>$$e^{-(-1)} = e^1 \approx 2.718$$</li>
          <li>$$e^{-(-0.5)} = e^{0.5} \approx 1.649$$</li>
      </ul>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 3:</strong> A neuron has three inputs $$x_1, x_2, x_3$$.<br>
              Given:<br>
              - $$x_1 = 1$$, $$x_2 = -1$$, $$x_3 = 2$$<br>
              - $$w_1 = 0.5$$, $$w_2 = 1.0$$, $$w_3 = -0.2$$<br>
              - $$b = 0.1$$</p>
              <p>Calculate $$z$$ and then $$a = \phi(z)$$ using the Sigmoid function. You can round $$a$$ to 3 decimal places.</p>
          </div>
          <div class="answer-field">
              <label for="z_3">Net Input z:</label>
              <input type="number" id="z_3" step="0.1">
          </div>
          <div class="answer-field">
              <label for="a_3">Activation a (3 dec places):</label>
              <input type="number" id="a_3" step="0.001">
          </div>
          <button class="check-button" onclick="checkAnswer('problem3', ['z_3', 'a_3'], [-0.8, 0.310], [0, 0.001])">Check Answer</button>
          <div id="feedback-problem3" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem3')">Show Solution</button>
          <div id="solution-problem3" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Calculate net input $$z$$:</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + (w_3 x_3) + b \]</p>
              <p>Substitute values:</p>
              <p>\[ z = (0.5 \times 1) + (1.0 \times -1) + (-0.2 \times 2) + 0.1 \]</p>
              <p>Perform multiplications:</p>
              <p>\[ z = 0.5 - 1.0 - 0.4 + 0.1 \]</p>
              <p>Calculate the sum:</p>
              <p>\[ z = -0.8 \]</p>
              <p>2. Apply Sigmoid Activation $$a = \phi(z) = 1 / (1 + e^{-z})$$:</p>
              <p>We need $$e^{-z} = e^{-(-0.8)} = e^{0.8}$$.<br>
              (Using a calculator, $$e^{0.8} \approx 2.2255$$)</p>
              <p>\[ a = \frac{1}{1 + e^{-(-0.8)}} = \frac{1}{1 + e^{0.8}} \approx \frac{1}{1 + 2.2255} = \frac{1}{3.2255} \]</p>
              <p>Final activation:</p>
              <p>\[ a \approx 0.310 \]</p>
              <p><strong>Final Answer:</strong> $$z = -0.8$$, $$a \approx 0.310$$</p>
          </div>
      </div>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 4:</strong> Another Sigmoid neuron, two inputs.<br>
              Given:<br>
              - $$x_1 = 2$$, $$x_2 = 1$$<br>
              - $$w_1 = 1.5$$, $$w_2 = -1.0$$<br>
              - $$b = -1.5$$</p>
              <p>Calculate $$z$$ and $$a = \phi(z)$$ (Sigmoid). Round $$a$$ to 3 decimal places.</p>
          </div>
          <div class="answer-field">
              <label for="z_4">Net Input z:</label>
              <input type="number" id="z_4" step="0.1">
          </div>
          <div class="answer-field">
              <label for="a_4">Activation a (3 dec places):</label>
              <input type="number" id="a_4" step="0.001">
          </div>
          <button class="check-button" onclick="checkAnswer('problem4', ['z_4', 'a_4'], [0.5, 0.622], [0, 0.001])">Check Answer</button>
          <div id="feedback-problem4" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem4')">Show Solution</button>
          <div id="solution-problem4" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Calculate $$z$$:</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + b \]</p>
              <p>Substitute:</p>
              <p>\[ z = (1.5 \times 2) + (-1.0 \times 1) + (-1.5) \]</p>
              <p>Multiply:</p>
              <p>\[ z = 3.0 - 1.0 - 1.5 \]</p>
              <p>Sum:</p>
              <p>\[ z = 0.5 \]</p>
              <p>2. Apply Sigmoid Activation $$a = \phi(z) = 1 / (1 + e^{-z})$$:</p>
              <p>We need $$e^{-z} = e^{-0.5}$$. From our list, this is $$\approx 0.6065$$ (or you could use the provided $$e^{0.5} \approx 1.649$$ and calculate $$1/1.649$$).<br>
              Let's use $$e^{-0.5} \approx 0.6065$$.</p>
              <p>\[ a = \frac{1}{1 + e^{-0.5}} \approx \frac{1}{1 + 0.6065} = \frac{1}{1.6065} \]</p>
              <p>Final activation:</p>
              <p>\[ a \approx 0.622 \]</p>
              <p><strong>Final Answer:</strong> $$z = 0.5$$, $$a \approx 0.622$$</p>
          </div>
      </div>
      
      <p>The Sigmoid calculations involve a bit more arithmetic with $$e$$, but the principle is the same! Notice how the output $$a$$ is always between 0 and 1.</p>
      <div class="continue-button" onclick="showNextSection(5)">Continue</div>
  </section>

  <section id="section5">
      <h2>Difficulty 3: Working Backwards (A Little Teaser!)</h2>
      <p>Now for a bit of a brain-teaser! This is a little taste of the kind of thinking involved when networks <em>learn</em> (though much simpler!). For these problems, we'll go back to the <strong>Step Activation Function</strong> ($$a=1$$ if $$z \geq 0$$, $$a=0$$ if $$z < 0$$).</p>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 5:</strong> A neuron has two inputs, $$x_1$$ and $$x_2$$.<br>
              Given:<br>
              - Input 1: $$x_1 = 1$$<br>
              - Input 2: $$x_2 = 1$$<br>
              - Weight for x2: $$w_2 = -0.5$$<br>
              - Bias: $$b = 0.3$$<br>
              - Desired Activation: $$a = 1$$ (using Step Activation)</p>
              <p>What is the <em>smallest integer value</em> for $$w_1$$ that will make the neuron output $$a = 1$$?</p>
          </div>
          <div class="answer-field">
              <label for="w1_5">Smallest integer w1:</label>
              <input type="number" id="w1_5" step="1">
          </div>
          <button class="check-button" onclick="checkAnswer('problem5', ['w1_5'], [1])">Check Answer</button>
          <div id="feedback-problem5" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem5')">Show Solution</button>
          <div id="solution-problem5" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Condition for $$a=1$$ with Step Activation:</p>
              <p>For $$a$$ to be 1, the net input $$z$$ must be $$\geq 0$$.</p>
              <p>\[ z = (w_1 x_1) + (w_2 x_2) + b \geq 0 \]</p>
              <p>2. Substitute known values:</p>
              <p>\[ (w_1 \times 1) + (-0.5 \times 1) + 0.3 \geq 0 \]</p>
              <p>Simplify:</p>
              <p>\[ w_1 - 0.5 + 0.3 \geq 0 \newline w_1 - 0.2 \geq 0 \]</p>
              <p>3. Solve for $$w_1$$:</p>
              <p>\[ w_1 \geq 0.2 \]</p>
              <p>4. Smallest Integer Value:</p>
              <p>The smallest integer $$w_1$$ that satisfies $$w_1 \geq 0.2$$ is 1.</p>
              <p><strong>Final Answer:</strong> $$w_1 = 1$$</p>
          </div>
      </div>
      
      <div class="exercise-problem">
          <div class="problem-statement">
              <p><strong>Problem 6:</strong> A neuron has one input $$x_1$$.<br>
              Given:<br>
              - Input 1: $$x_1 = 2$$<br>
              - Weight for x1: $$w_1 = -3$$<br>
              - Desired Activation: $$a = 0$$ (using Step Activation)</p>
              <p>What is the <em>largest integer value</em> for the bias $$b$$ that will make the neuron output $$a = 0$$?</p>
          </div>
          <div class="answer-field">
              <label for="b_6">Largest integer b:</label>
              <input type="number" id="b_6" step="1">
          </div>
          <button class="check-button" onclick="checkAnswer('problem6', ['b_6'], [5])">Check Answer</button>
          <div id="feedback-problem6" class="feedback"></div>
          <button class="reveal-button" onclick="revealAnswer('solution-problem6')">Show Solution</button>
          <div id="solution-problem6" style="display: none;">
              <h4>Solution:</h4>
              <p>1. Condition for $$a=0$$ with Step Activation:</p>
              <p>For $$a$$ to be 0, the net input $$z$$ must be $$< 0$$.</p>
              <p>\[ z = (w_1 x_1) + b < 0 \]</p>
              <p>2. Substitute known values:</p>
              <p>\[ (-3 \times 2) + b < 0 \]</p>
              <p>Simplify:</p>
              <p>\[ -6 + b < 0 \]</p>
              <p>3. Solve for $$b$$:</p>
              <p>\[ b < 6 \]</p>
              <p>4. Largest Integer Value:</p>
              <p>The largest integer $$b$$ that satisfies $$b < 6$$ is 5.</p>
              <p><strong>Final Answer:</strong> $$b = 5$$</p>
          </div>
      </div>
      
      <p>Those last ones required a bit more algebraic thinking! It's like figuring out how to tune the neuron's 'knobs' ($$w$$ and $$b$$) to get a desired outcome.</p>
      <div class="continue-button" onclick="showNextSection(6)">Continue</div>
  </section>

  <section id="section6">
      <h2>Great Job, Neuron Mechanic!</h2>
      <p>Fantastic work going through those calculations!</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A gold medal icon with a neuron symbol in the center, or a character giving a thumbs up next to a correctly solved equation.">
      </div>
      <p>By calculating the net input $$z$$ and then applying an activation function $$\phi$$ to get the output $$a$$, you've performed the core computation of an artificial neuron. Understanding this process inside-out is fundamental, as it's what happens countless times within larger, multi-layered neural networks.</p>
      <p><strong>Key Takeaways from this Exercise:</strong></p>
      <ul>
          <li>The net input $$z$$ is a linear combination of inputs, weights, and bias.</li>
          <li>The activation function $$\phi$$ introduces non-linearity (usually, except for Identity) and determines the final output $$a$$.</li>
          <li>Different activation functions (Step, Sigmoid) lead to different output behaviors and ranges.</li>
      </ul>
      <p>In our upcoming lessons, we'll see how these individual neuron calculations are efficiently handled for entire layers using matrix notation, and then we'll start building more complex networks!</p>
      
      <div class="faq-section">
          <h3>Frequently Asked Questions</h3>
          <h4>Why are there so many different activation functions if they all just take $$z$$ and produce $$a$$?</h4>
          <p>That's a great question! While the basic flow is $$z \rightarrow \phi \rightarrow a$$, the <em>shape</em> and <em>mathematical properties</em> of $$\phi$$ matter a lot:</p>
          <ol>
              <li><strong>Output Range:</strong> Some problems need outputs in (0,1) (like probabilities from Sigmoid), others in (-1,1) (Tanh), or unbounded (Identity for regression), or non-negative (ReLU).</li>
              <li><strong>Non-Linearity:</strong> Different non-linearities allow the network to learn different kinds of complex patterns.</li>
              <li><strong>Gradient Properties:</strong> The derivative of the activation function is crucial for training. Functions like ReLU help with the 'vanishing gradient' problem more than Sigmoid/Tanh in deep networks.</li>
              <li><strong>Computational Cost:</strong> Simpler functions like ReLU are faster to compute.</li>
          </ol>
          <p>So, the choice depends on the specific needs of the layer and the overall network architecture!</p>
      </div>
  </section>

  <script>
      // Show the first section initially
      document.getElementById("section1").style.display = "block";
      document.getElementById("section1").style.opacity = "1";

      function showNextSection(nextSectionId) {
          const currentButton = event.target;
          const nextSection = document.getElementById("section" + nextSectionId);
          
          currentButton.style.display = "none";
          
          nextSection.style.display = "block";
          setTimeout(() => {
              nextSection.style.opacity = "1";
          }, 10);

          setTimeout(() => {
              nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }, 500);
      }

      function revealAnswer(id) {
          const revealText = document.getElementById(id);
          const revealButton = event.target;
          
          revealText.style.display = "block";
          revealButton.style.display = "none";
      }
      
      function checkAnswer(problemId, inputIds, correctAnswers, tolerances = []) {
          let allCorrect = true;
          
          for (let i = 0; i < inputIds.length; i++) {
              const inputElement = document.getElementById(inputIds[i]);
              const userAnswer = parseFloat(inputElement.value);
              const correctAnswer = correctAnswers[i];
              const tolerance = tolerances[i] || 0;
              
              if (isNaN(userAnswer) || Math.abs(userAnswer - correctAnswer) > tolerance) {
                  allCorrect = false;
                  break;
              }
          }
          
          const feedbackElement = document.getElementById("feedback-" + problemId);
          
          if (allCorrect) {
              feedbackElement.textContent = "Correct! Great job!";
              feedbackElement.className = "feedback correct";
          } else {
              feedbackElement.textContent = "Not quite right. Try again or check the solution.";
              feedbackElement.className = "feedback incorrect";
          }
          
          feedbackElement.style.display = "block";
      }
  </script>
</body>
</html>