<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Artificial Neuron: A Mathematical Model</title>
  <style>
      body {
          font-family: Arial, sans-serif;
          max-width: 800px;
          margin: 0 auto;
          padding: 20px;
          background-color: #ffffff;
          font-size: 150%;
      }
      section {
          margin-bottom: 20px;
          padding: 20px;
          background-color: #ffffff;
          display: none;
          opacity: 0;
          transition: opacity 0.5s ease-in;
      }
      h1, h2, h3, h4 {
          color: #333;
          margin-top: 20px;
      }
      p, li {
          line-height: 1.6;
          color: #444;
          margin-bottom: 20px;
      }
      ul {
          padding-left: 20px;
      }
      .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          text-align: left;
      }
      .image-placeholder img, .interactive-placeholder img {
          max-width: 100%;
          height: auto;
          border-radius: 5px;
      }
      .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
          padding: 20px;
          border-radius: 8px;
          margin-top: 20px;
      }
      .vocab-section {
          background-color: #f0f8ff;
      }
      .vocab-section h3 {
          color: #1e90ff;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .vocab-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .vocab-term {
          font-weight: bold;
          color: #1e90ff;
      }
      .why-it-matters {
          background-color: #ffe6f0;
      }
      .why-it-matters h3 {
          color: #d81b60;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .stop-and-think {
          background-color: #e6e6ff;
      }
      .stop-and-think h3 {
          color: #4b0082;
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .continue-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #007bff;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .reveal-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #4b0082;
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
      }
      .test-your-knowledge {
          background-color: #e6ffe6; /* Light green background */
      }
      .test-your-knowledge h3 {
          color: #28a745; /* Dark green heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .test-your-knowledge h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .test-your-knowledge p {
          margin-bottom: 15px;
      }
      .check-button {
          display: inline-block;
          padding: 10px 20px;
          margin-top: 15px;
          color: #ffffff;
          background-color: #28a745; /* Green background */
          border-radius: 5px;
          text-decoration: none;
          cursor: pointer;
          border: none;
          font-size: 1em;
      }
      .faq-section {
          background-color: #fffbea; /* Light yellow background */
      }
      .faq-section h3 {
          color: #ffcc00; /* Bright yellow heading */
          font-size: 0.75em;
          margin-bottom: 5px;
          margin-top: 5px;
      }
      .faq-section h4 {
          color: #000;
          font-size: 0.9em;
          margin-top: 10px;
          margin-bottom: 8px;
      }
      .interactive-neuron {
          border: 1px solid #ddd;
          padding: 20px;
          border-radius: 8px;
          background-color: #f9f9f9;
          margin-bottom: 20px;
      }
      .slider-container {
          margin-bottom: 15px;
      }
      .slider-container label {
          display: inline-block;
          width: 50px;
          font-weight: bold;
      }
      .slider-container input[type="range"] {
          width: 200px;
          margin: 0 10px;
      }
      .slider-container span {
          width: 40px;
          display: inline-block;
      }
      .calculation-display {
          background-color: #fff;
          border: 1px solid #ddd;
          padding: 15px;
          border-radius: 5px;
          margin-top: 15px;
          font-family: monospace;
          font-size: 1.1em;
      }
      .output-display {
          background-color: #f0f8ff;
          border: 1px solid #1e90ff;
          padding: 15px;
          border-radius: 5px;
          margin-top: 15px;
          font-weight: bold;
          text-align: center;
          font-size: 1.2em;
      }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <section id="section1">
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A sleek, glowing abstract representation of an artificial neuron with data streams flowing into it and a processed signal flowing out. Caption: 'The Digital Brain Cell: Simplified, Powerful.'">
      </div>
      <h1>The Artificial Neuron: A Mathematical Model</h1>
      <p>Alright, team! We've just marveled at the biological neuron, nature's tiny processing marvel. Now, it's time to see how we take that beautiful inspiration and build our own version – a much simpler, mathematical one, but incredibly powerful in its own right: the <strong>artificial neuron</strong>.</p>
      <p>Sometimes, especially in its early and simplest forms, you'll also hear this basic unit called a <strong>perceptron</strong>. We're going to dissect it piece by piece, look at the math that makes it tick, and understand why each component is crucial. Let's get to it!</p>
      <div class="continue-button" onclick="showNextSection(2)">Continue</div>
  </section>

  <section id="section2">
      <h2>Anatomy of an Artificial Neuron</h2>
      <p>So, what does our artificial neuron look like? It's a lot less squishy than the biological one, and a lot more... diagrammatic!</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="An animated diagram of an artificial neuron, building up step-by-step with inputs, weights, bias, summation, and activation function">
      </div>
      <p>Let's break down these components:</p>
      <ul>
          <li><strong>Inputs (x):</strong> These are the numerical values that our neuron receives. If we're classifying marbles, these could be the mass and diameter. If it's an image, they could be pixel values. We usually denote them as $$x_1, x_2, ..., x_m$$.</li>
          <li><strong>Weights (w):</strong> Each input $$x_i$$ is connected to the neuron by a pathway that has an associated <strong>weight $$w_i$$</strong>. Think of a weight as a knob that controls the <em>strength</em> or <em>importance</em> of that particular input. A large positive weight means that input strongly excites the neuron. A large negative weight means that input strongly inhibits it. A weight near zero means that input doesn't have much effect.</li>
          <li><strong>Bias (b):</strong> This is a special, extra input that's always set to 1, and it has its own dedicated weight, called the <strong>bias $$b$$</strong>. The bias term is super important! It allows the neuron to shift its activation threshold. Without it, the neuron's decision boundary would always have to pass through the origin (0,0 in a 2D case), which is very limiting. The bias gives the neuron more flexibility to fit the data.</li>
      </ul>
      <div class="vocab-section">
          <h3>Build Your Vocab</h3>
          <h4 class="vocab-term">Weights & Bias</h4>
          <p>In an artificial neuron, <strong>weights</strong> are numerical values that determine the strength and direction (excitatory or inhibitory) of the connection from an input. The <strong>bias</strong> is an additional parameter that allows the neuron to be activated even when all inputs are zero, or to shift the activation function horizontally. Both weights and bias are <em>learnable parameters</em> – the network adjusts them during training to improve its performance.</p>
      </div>
      <div class="continue-button" onclick="showNextSection(3)">Continue</div>
  </section>

  <section id="section3">
      <h2>The Two-Step Calculation Dance</h2>
      <p>Now for the core of the neuron's operation! It performs a two-step calculation to arrive at its output.</p>
      <p>Imagine the inputs and their weights all flowing into the neuron. Here's what happens inside:</p>
      
      <h3>Neuron's Calculation Process</h3>
      
      <h4>Step 1: The Weighted Sum (Net Input $$z$$)</h4>
      <p>First, the neuron calculates the <strong>weighted sum</strong> of all its inputs. This means it multiplies each input $$x_i$$ by its corresponding weight $$w_i$$, and then sums up all these products. Finally, it adds the bias $$b$$ (which is essentially $$b \times 1$$). This result is often called the 'net input' or 'logit', and we'll denote it as $$z$$.</p>
      <p>\[ z = (w_1 \times x_1) + (w_2 \times x_2) + \dots + (w_m \times x_m) + b \]</p>
      <p>Or more compactly:</p>
      <p>\[ z = \sum_{i=1}^{m} (w_i x_i) + b \]</p>
      
      <h4>Example Calculation for $$z$$</h4>
      <p>Let's make this concrete! Suppose our neuron has two inputs, $$x_1$$ and $$x_2$$, plus a bias:</p>
      <ul>
          <li>Input 1: $$x_1 = 0.5$$</li>
          <li>Input 2: $$x_2 = 1.0$$</li>
      </ul>
      <p>And the neuron has these parameters:</p>
      <ul>
          <li>Weight for $$x_1$$: $$w_1 = 2.0$$</li>
          <li>Weight for $$x_2$$: $$w_2 = -1.0$$</li>
          <li>Bias: $$b = 0.7$$</li>
      </ul>
      <p>Now, let's calculate $$z$$:</p>
      <p>\[ z = (w_1 \times x_1) + (w_2 \times x_2) + b \newline z = (2.0 \times 0.5) + (-1.0 \times 1.0) + 0.7 \newline z = 1.0 - 1.0 + 0.7 \newline z = 0.7 \]</p>
      
      <h4>Step 2: The Activation Function ($$\phi$$)</h4>
      <p>Okay, we have our net input $$z = 0.7$$. But the neuron isn't done yet! This value $$z$$ is then passed through an <strong>activation function</strong>, denoted by the Greek letter $$\phi$$ (phi). The activation function takes $$z$$ and transforms it into the neuron's final output, $$a$$.</p>
      <p>\[ a = \phi(z) \]</p>
      
      <h4>Putting It All Together</h4>
      <p>So, the complete mathematical expression for the output $$a$$ of our artificial neuron is:</p>
      <p>\[ a = \phi \left( \left( \sum_{i=1}^{m} w_i x_i \right) + b \right) \]</p>
      
      <h4>What IS this Activation Function $$\phi$$?</h4>
      <p>Good question! We'll dedicate whole future lessons to different types of activation functions (like Sigmoid, ReLU, Tanh). For now, just know that they are typically <strong>non-linear</strong> functions. This non-linearity is absolutely CRUCIAL. Without it, a multi-layered neural network would just behave like a single-layer one, no matter how many layers you stack! Activation functions allow networks to learn complex, curvy decision boundaries and model intricate patterns. Think of $$\phi$$ as the neuron's way of deciding how strongly to 'fire' or 'activate' based on its net input $$z$$.</p>
      
      <div class="continue-button" onclick="showNextSection(4)">Continue</div>
  </section>

  <section id="section4">
      <h2>Play with a Neuron!</h2>
      <p>Let's make this even more hands-on. Try adjusting the inputs, weights, and bias for a simple neuron below and see how the net input $$z$$ changes. For now, we'll use a very simple 'Step' activation function for $$\phi$$: if $$z \geq 0$$, output $$a=1$$; otherwise, output $$a=0$$.</p>
      
      <div class="interactive-neuron">
          <h3>Interactive Neuron Calculator</h3>
          
          <div class="slider-container">
              <label for="x1">x₁:</label>
              <input type="range" id="x1" min="-2" max="2" step="0.1" value="0.5" oninput="updateNeuron()">
              <span id="x1-value">0.5</span>
          </div>
          
          <div class="slider-container">
              <label for="x2">x₂:</label>
              <input type="range" id="x2" min="-2" max="2" step="0.1" value="1.0" oninput="updateNeuron()">
              <span id="x2-value">1.0</span>
          </div>
          
          <div class="slider-container">
              <label for="w1">w₁:</label>
              <input type="range" id="w1" min="-3" max="3" step="0.1" value="2.0" oninput="updateNeuron()">
              <span id="w1-value">2.0</span>
          </div>
          
          <div class="slider-container">
              <label for="w2">w₂:</label>
              <input type="range" id="w2" min="-3" max="3" step="0.1" value="-1.0" oninput="updateNeuron()">
              <span id="w2-value">-1.0</span>
          </div>
          
          <div class="slider-container">
              <label for="b">b:</label>
              <input type="range" id="b" min="-3" max="3" step="0.1" value="0.7" oninput="updateNeuron()">
              <span id="b-value">0.7</span>
          </div>
          
          <div class="calculation-display" id="calculation">
              z = (2.0 * 0.5) + (-1.0 * 1.0) + 0.7 = 0.7
          </div>
          
          <div class="output-display" id="output">
              Output (a) = 1
          </div>
      </div>
      
      <p>Notice how changing the weights influences how much each input contributes, and how the bias can shift the point at which the neuron activates. These $$w$$'s and $$b$$ are precisely what the neural network learns during its training process – it's trying to find the best 'settings' for these knobs to solve the problem at hand!</p>
      
      <div class="why-it-matters">
          <h3>Why It Matters</h3>
          <p>This simple mathematical model – inputs, weights, a bias, a sum, and an activation function – is the fundamental building block of even the most complex deep neural networks. Every single 'node' you see in those vast network diagrams is essentially doing this two-step calculation. Understanding this core unit is key to understanding everything that follows!</p>
      </div>
      
      <div class="continue-button" onclick="showNextSection(5)">Continue</div>
  </section>

  <section id="section5">
      <h2>What's Next?</h2>
      <p>Phew! We've successfully built our first artificial neuron from scratch (mathematically, at least!). We know its parts and how it computes an output.</p>
      <p>But one neuron, while cool, usually can't solve very complex problems on its own. The real magic begins when we start connecting many of these neurons together into <strong>layers</strong>, and then stack those layers to form a <strong>network</strong>.</p>
      <p>In our next lesson, we'll zoom out and see how these individual neurons are organized into the input, hidden, and output layers that make up a feedforward neural network. It's time to start weaving the web!</p>
      <div class="image-placeholder">
          <img src="/placeholder.svg?height=300&width=600" alt="A single, simple LEGO brick labeled 'Artificial Neuron'. Next to it, a complex and impressive LEGO castle labeled 'Neural Network', showing how simple blocks combine to make something amazing.">
      </div>
  </section>

  <script>
      // Show the first section initially
      document.getElementById("section1").style.display = "block";
      document.getElementById("section1").style.opacity = "1";

      function showNextSection(nextSectionId) {
          const currentButton = event.target;
          const nextSection = document.getElementById("section" + nextSectionId);
          
          currentButton.style.display = "none";
          
          nextSection.style.display = "block";
          setTimeout(() => {
              nextSection.style.opacity = "1";
          }, 10);

          setTimeout(() => {
              nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }, 500);
      }

      function revealAnswer(id) {
          const revealText = document.getElementById(id);
          const revealButton = event.target;
          
          revealText.style.display = "block";
          revealButton.style.display = "none";
      }
      
      function updateNeuron() {
          // Get all input values
          const x1 = parseFloat(document.getElementById("x1").value);
          const x2 = parseFloat(document.getElementById("x2").value);
          const w1 = parseFloat(document.getElementById("w1").value);
          const w2 = parseFloat(document.getElementById("w2").value);
          const b = parseFloat(document.getElementById("b").value);
          
          // Update display values
          document.getElementById("x1-value").textContent = x1.toFixed(1);
          document.getElementById("x2-value").textContent = x2.toFixed(1);
          document.getElementById("w1-value").textContent = w1.toFixed(1);
          document.getElementById("w2-value").textContent = w2.toFixed(1);
          document.getElementById("b-value").textContent = b.toFixed(1);
          
          // Calculate z (weighted sum)
          const z = (w1 * x1) + (w2 * x2) + b;
          
          // Calculate output using step activation function
          const a = z >= 0 ? 1 : 0;
          
          // Update calculation display
          document.getElementById("calculation").textContent = 
              `z = (${w1.toFixed(1)} * ${x1.toFixed(1)}) + (${w2.toFixed(1)} * ${x2.toFixed(1)}) + ${b.toFixed(1)} = ${z.toFixed(1)}`;
          
          // Update output display
          document.getElementById("output").textContent = `Output (a) = ${a}`;
          
          // Change color based on output
          document.getElementById("output").style.backgroundColor = a === 1 ? "#e6ffe6" : "#ffe6e6";
          document.getElementById("output").style.borderColor = a === 1 ? "#28a745" : "#dc3545";
      }
      
      // Initialize the neuron calculator
      updateNeuron();
  </script>
</body>
</html>