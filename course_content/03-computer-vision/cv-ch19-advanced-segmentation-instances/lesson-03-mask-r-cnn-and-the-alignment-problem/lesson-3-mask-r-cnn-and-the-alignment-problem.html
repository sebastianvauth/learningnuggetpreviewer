<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<link rel="stylesheet" href="../../styles/lesson.css">
<title>Mask R-CNN & The Alignment Problem</title>
<script>
window.MathJax = {
    tex: { inlineMath: [['\\(','\\)'], ['$', '$']] },
    options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
<div class="progress-container"><div class="progress-bar" id="progressBar"></div></div>
<div class="lesson-container">

<section id="section1" class="visible">
    <div class="image-placeholder">
        <img src="images/1.jpg" alt="Comparison of Faster R-CNN bounding boxes on the left and Mask R-CNN masks on the right">
    </div>
    <h1>Mask R-CNN & The Alignment Problem</h1>
    <h2>From Boxes to Shapes</h2>
    <p>We’ve spent some time mastering object detection. We know how to draw a bounding box around a car, a pedestrian, or a traffic light using Faster R-CNN. But let's be honest: the world isn't made of boxes.</p>
    <div class="continue-button" onclick="showNextSection(2)">Continue</div>
</section>

<section id="section2">
    <h2>The Architecture Upgrade</h2>
    <p>Imagine you are building a robot to pick strawberries. A bounding box tells the robot <em>roughly</em> where the strawberry is, but if the robot gripper tries to grab the whole box, it might crush the leaves or the stem. It needs the exact shape.</p>
    <div class="continue-button" onclick="showNextSection(3)">Continue</div>
</section>

<section id="section3">
    <p>To solve this, we introduce <strong>Mask R-CNN</strong>. It is an elegant extension of the object detectors we already know. It takes the existing Faster R-CNN architecture and adds a third branch.</p>
    <div class="continue-button" onclick="showNextSection(4)">Continue</div>
</section>

<section id="section4">
    <p>Previously, for every Region of Interest (RoI), we had two outputs:</p>
    <ol>
        <li><strong>Class Label:</strong> "This is a cat."</li>
        <li><strong>Bounding Box Offset:</strong> "Move the box 2 pixels right."</li>
    </ol>
    <div class="continue-button" onclick="showNextSection(5)">Continue</div>
</section>

<section id="section5">
    <p>Mask R-CNN adds a third parallel output:</p>
    <p>3. <strong>The Mask:</strong> "Here is the binary silhouette of the object."</p>
    <div class="visual-placeholder">
        <img src="images/2.jpg" alt="Diagram showing ROI features splitting into class, box, and mask prediction branches">
        <p class="image-caption">The three-branch head: classification, box regression, and the new mask decoder.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(6)">Continue</div>
</section>

<section id="section6">
    <p>The mask branch is a small Fully Convolutional Network (FCN) applied to each Region of Interest. Crucially, this branch is <strong>decoupled</strong> from the classification task.</p>
    <div class="vocab-section">
        <h3>Build Your Vocab</h3>
        <h4>Decoupled Mask Prediction</h4>
        <p>A design choice where the mask branch predicts a separate mask for every possible class independently, without knowing which class is the winner. The class selection is handled solely by the classification branch.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(7)">Continue</div>
</section>

<section id="section7">
    <p>This means if your dataset has 80 classes (like COCO), the mask branch actually generates 80 different binary masks for every single object! It asks: "If this is a person, here is the mask. If this is a car, here is the mask."</p>
    <div class="continue-button" onclick="showNextSection(8)">Continue</div>
</section>

<section id="section8">
    <p>The network relies on the classification branch to pick the winner and discards the other 79 masks.</p>
    <div class="test-your-knowledge">
        <h3>Test Your Knowledge</h3>
        <h4>True or False: The mask prediction branch determines whether the object is a 'Cat' or a 'Dog'.</h4>
        <div class="multiple-choice">
            <div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Not quite. The mask branch just draws shapes. It relies on the separate classification branch to decide what the object actually is.')">True</div>
            <div class="choice-option" data-correct="true" onclick="selectChoice(this, true, 'Correct! The classification branch figures out the label. The mask branch just provides the shape for that specific label.')">False</div>
        </div>
    </div>
    <div class="continue-button" id="continue-after-q1" onclick="showNextSection(9)" style="display: none;">Continue</div>
</section>

<section id="section9">
    <h2>The Math of Multi-Task Loss</h2>
    <p>Because we are now asking the network to do three things at once, we need a loss function that balances them all. We define a Multi-Task Loss equation ($L$) as the sum of the individual losses:</p>
    <p>\[ L = L_{cls} + L_{box} + L_{mask} \]</p>
    <div class="continue-button" onclick="showNextSection(10)">Continue</div>
</section>

<section id="section10">
    <p>We already know $L_{cls}$ (Classification Cross-Entropy) and $L_{box}$ (Bounding Box Regression). Let's zoom in on the new term, $L_{mask}$.</p>
    <p>$L_{mask}$ is defined as the <strong>Average Binary Cross-Entropy Loss</strong>. Since the mask is binary (a pixel is either 'object' or 'background'), we treat every pixel in the mask like a tiny coin flip.</p>
    <div class="continue-button" onclick="showNextSection(11)">Continue</div>
</section>

<section id="section11">
    <p>Here is the clever part regarding the decoupling we mentioned earlier. Let's calculate the loss for a specific example:</p>
    <ul>
        <li>The Ground Truth says the object is a <strong>Cat</strong>.</li>
        <li>The Classification branch predicts <strong>Cat</strong>.</li>
        <li>The Mask branch generates 80 masks (one for Cat, one for Dog, one for Car, etc.).</li>
    </ul>
    <p>When calculating the loss, we select <em>only</em> the <strong>Cat</strong> mask to compare against the ground truth. If the 'Dog' mask was completely messy, we don't care. We don't penalize the network for a bad 'Dog' mask when the object is actually a 'Cat'.</p>
    <div class="continue-button" onclick="showNextSection(12)">Continue</div>
</section>

<section id="section12">
    <div class="check-your-knowledge">
        <h3>Stop and Think</h3>
        <h4>Why might it be harder to train the network if we penalized it for all 80 masks instead of just the correct class?</h4>
        <div id="cuy-loss-answer" style="display:none;" class="animate-in">
            <strong>Answer:</strong> If we penalized all masks, the network would have to learn to output 'blank' or 'background' for all the incorrect classes (e.g., the Dog mask for a Cat image). This wastes capacity. By only focusing on the correct class, the network learns specific shapes for specific objects more efficiently.
        </div>
        <button class="reveal-button" onclick="revealAnswer('cuy-loss-answer')">Reveal Answer</button>
    </div>
    <div class="continue-button" onclick="showNextSection(13)">Continue</div>
</section>

<section id="section13">
    <h2>The Alignment Problem</h2>
    <p>So, we have the architecture and the math. But if we just attach this mask head to the older Faster R-CNN architecture, the results look... slightly wrong. The masks don't line up perfectly with the objects.</p>
    <p>The culprit is a layer called <strong>RoI Pooling</strong>. In standard object detection, we just need a box. If the box is off by a fraction of a pixel, nobody notices. But in segmentation, pixel-perfect alignment is critical.</p>
    <div class="continue-button" onclick="showNextSection(14)">Continue</div>
</section>

<section id="section14">
    <p>RoI Pooling performs <strong>Quantization</strong>. It rounds floating-point coordinates to the nearest integer. Let's say a proposal box has a width of 20 pixels, and we want to pool it into a 7x7 grid.</p>
    <p>\[ 20 / 7 \approx 2.857 \]</p>
    <p>RoI Pooling rounds this. It might take a region of 2 pixels, or 3 pixels. It snaps the grid to integers. This rounding introduces a misalignment between the original image and the features we extract.</p>
    <div class="continue-button" onclick="showNextSection(15)">Continue</div>
</section>

<section id="section15">
    <!-- START: RoI Pooling vs Align Interactive -->
<div class="roi-interactive-container">
  <div class="roi-controls">
    <button class="roi-mode-btn active" onclick="setRoiMode('pooling')">Mode A: RoI Pooling</button>
    <button class="roi-mode-btn" onclick="setRoiMode('align')">Mode B: RoI Align</button>
  </div>

  <canvas id="roiCanvas" width="500" height="400"></canvas>
  
  <div class="roi-caption" id="roiCaption">
    Drag the box. Notice how it snaps to grid lines, missing the object edge.
  </div>
  <div class="roi-stats" id="roiStats">
    x: 0.00, y: 0.00
  </div>
</div>

<script>
(function() {
  const canvas = document.getElementById('roiCanvas');
  const ctx = canvas.getContext('2d');
  const caption = document.getElementById('roiCaption');
  const stats = document.getElementById('roiStats');
  
  // Configuration
  const GRID_SIZE = 40; // Size of one "pixel"
  const BOX_W = 3.5 * GRID_SIZE; // 3.5 units wide (non-integer to force snapping issues)
  const BOX_H = 3.5 * GRID_SIZE; 
  
  let mode = 'pooling'; // 'pooling' or 'align'
  
  // State
  let box = {
    x: 180, // Start somewhere in the middle
    y: 130,
    isDragging: false,
    dragOffsetX: 0,
    dragOffsetY: 0
  };

  // High-DPI Canvas Setup
  function resizeCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    canvas.width = 500 * dpr;
    canvas.height = 400 * dpr;
    ctx.scale(dpr, dpr);
    canvas.style.width = '500px';
    canvas.style.height = '400px';
    draw();
  }

  // Draw Function
  function draw() {
    ctx.clearRect(0, 0, 500, 400);

    // 1. Draw Grid (The "Pixels")
    ctx.strokeStyle = '#e2e8f0';
    ctx.lineWidth = 1;
    ctx.beginPath();
    for(let x = 0; x <= 500; x += GRID_SIZE) {
      ctx.moveTo(x, 0); ctx.lineTo(x, 400);
    }
    for(let y = 0; y <= 400; y += GRID_SIZE) {
      ctx.moveTo(0, y); ctx.lineTo(500, y);
    }
    ctx.stroke();

    // 2. Draw "The Object" (A curved shape)
    // We draw an organic blob-like shape
    ctx.fillStyle = '#ebf8ff'; // Very light blue fill
    ctx.strokeStyle = '#3182ce'; // Blue border
    ctx.lineWidth = 3;
    
    ctx.beginPath();
    ctx.moveTo(150, 100);
    ctx.bezierCurveTo(250, 50, 400, 150, 350, 250);
    ctx.bezierCurveTo(300, 350, 150, 350, 100, 250);
    ctx.bezierCurveTo(50, 150, 100, 100, 150, 100);
    ctx.fill();
    ctx.stroke();

    // 3. Calculate Box Position based on Mode
    let renderX, renderY;
    
    if (mode === 'pooling') {
      // QUANTIZATION logic: Round to nearest grid unit
      renderX = Math.round(box.x / GRID_SIZE) * GRID_SIZE;
      renderY = Math.round(box.y / GRID_SIZE) * GRID_SIZE;
      
      // Visualizing the "Lost" area (optional ghost box)
      ctx.save();
      ctx.strokeStyle = 'rgba(0,0,0,0.1)';
      ctx.setLineDash([5, 5]);
      ctx.strokeRect(box.x, box.y, BOX_W, BOX_H);
      ctx.restore();
      
    } else {
      // ALIGN logic: Floating point precision
      renderX = box.x;
      renderY = box.y;
    }

    // 4. Draw the Selection Box
    ctx.shadowColor = 'rgba(0, 0, 0, 0.2)';
    ctx.shadowBlur = 15;
    
    if (mode === 'pooling') {
      ctx.strokeStyle = '#e53e3e'; // Red for "Bad/Snapped"
      ctx.lineWidth = 4;
    } else {
      ctx.strokeStyle = '#805ad5'; // Purple for "Good/Align"
      ctx.lineWidth = 4;
    }
    
    ctx.strokeRect(renderX, renderY, BOX_W, BOX_H);
    ctx.shadowBlur = 0; // Reset shadow

    // 5. Draw Sampling Points (Only for Align Mode)
    if (mode === 'align') {
      // Simulate a 2x2 output bin
      const binW = BOX_W / 2;
      const binH = BOX_H / 2;
      
      ctx.fillStyle = '#d6bcfa'; // Light purple dots
      
      // Loop through the 2x2 bins
      for(let i=0; i<2; i++) {
        for(let j=0; j<2; j++) {
          let binX = renderX + (i * binW);
          let binY = renderY + (j * binH);
          
          // Draw grid lines for the bins inside the RoI
          ctx.save();
          ctx.strokeStyle = 'rgba(128, 90, 213, 0.3)';
          ctx.lineWidth = 1;
          ctx.strokeRect(binX, binY, binW, binH);
          ctx.restore();

          // Draw 4 sampling points per bin (bilinear interpolation points)
          // Usually at 0.25 and 0.75 of the bin size
          const offsets = [0.25, 0.75];
          ctx.fillStyle = '#38a169'; // Green dots
          
          offsets.forEach(ox => {
            offsets.forEach(oy => {
              ctx.beginPath();
              ctx.arc(binX + (binW * ox), binY + (binH * oy), 3, 0, Math.PI * 2);
              ctx.fill();
            });
          });
        }
      }
    }
    
    // Update Stats text
    const gridX = (renderX / GRID_SIZE).toFixed(2);
    const gridY = (renderY / GRID_SIZE).toFixed(2);
    stats.innerHTML = `Grid Coord: x=${gridX}, y=${gridY} ${mode === 'pooling' ? '(Snapped)' : '(Exact)'}`;
  }

  // Event Listeners
  function getMousePos(evt) {
    const rect = canvas.getBoundingClientRect();
    const scaleX = canvas.width / rect.width; // Relationship bitmap vs. element for X
    const scaleY = canvas.height / rect.height;
    
    // Handle touch or mouse
    const clientX = evt.touches ? evt.touches[0].clientX : evt.clientX;
    const clientY = evt.touches ? evt.touches[0].clientY : evt.clientY;

    return {
      x: (clientX - rect.left) * (500 / rect.width), // Normalize to logical 500 width
      y: (clientY - rect.top) * (400 / rect.height)
    };
  }

  function onDown(e) {
    e.preventDefault(); // Prevent scrolling on touch
    const pos = getMousePos(e);
    
    // Simple hit detection
    // In pooling mode, we check against the snapped box visually, but for dragging logic 
    // it feels better to grab the "ghost" (actual mouse pos) box.
    // Let's just check if mouse is roughly inside box area.
    if (pos.x >= box.x && pos.x <= box.x + BOX_W &&
        pos.y >= box.y && pos.y <= box.y + BOX_H) {
      box.isDragging = true;
      box.dragOffsetX = pos.x - box.x;
      box.dragOffsetY = pos.y - box.y;
      canvas.style.cursor = 'grabbing';
    }
  }

  function onMove(e) {
    if (!box.isDragging) return;
    e.preventDefault();
    const pos = getMousePos(e);
    
    // Update raw position
    box.x = pos.x - box.dragOffsetX;
    box.y = pos.y - box.dragOffsetY;
    
    // Keep in bounds
    if(box.x < 0) box.x = 0;
    if(box.y < 0) box.y = 0;
    if(box.x > 500 - BOX_W) box.x = 500 - BOX_W;
    if(box.y > 400 - BOX_H) box.y = 400 - BOX_H;
    
    draw();
  }

  function onUp() {
    box.isDragging = false;
    canvas.style.cursor = 'grab';
  }

  // Global exposure for buttons
  window.setRoiMode = function(newMode) {
    mode = newMode;
    const btns = document.querySelectorAll('.roi-mode-btn');
    btns.forEach(b => b.classList.remove('active'));
    // Simple index check or text check
    if(mode === 'pooling') btns[0].classList.add('active');
    else btns[1].classList.add('active');
    
    if(mode === 'pooling') {
      caption.innerHTML = "Drag the box. Notice how it <strong>snaps</strong> to grid lines. <br>This causes misalignment with the underlying shape.";
    } else {
      caption.innerHTML = "Drag the box. It moves <strong>smoothly</strong>.<br>The green dots represent the bilinear sampling points calculated at exact floating-point coordinates.";
    }
    
    draw();
  };

  canvas.addEventListener('mousedown', onDown);
  canvas.addEventListener('mousemove', onMove);
  window.addEventListener('mouseup', onUp);
  
  canvas.addEventListener('touchstart', onDown, {passive: false});
  canvas.addEventListener('touchmove', onMove, {passive: false});
  window.addEventListener('touchend', onUp);

  // Init
  resizeCanvas();
  // Ensure we draw once images/fonts are ready (though here we only use shapes)
  requestAnimationFrame(draw);

})();
</script>
<!-- END: RoI Pooling vs Align Interactive -->
    <p>In the 'Pooling' mode, notice how the box snapped to the grid lines? That snapping action throws away spatial information. In 'Align' mode, the box floated freely.</p>
    <div class="continue-button" onclick="showNextSection(16)">Continue</div>
</section>

<section id="section16">
    <p>To fix this, Mask R-CNN replaces RoI Pooling with <strong>RoIAlign</strong>. RoIAlign removes quantization. It allows the boundaries of the extracted region to float at exact coordinates, like \( x=2.857 \).</p>
    <p>Since we can't extract a value from 'half a pixel', RoIAlign uses <strong>Bilinear Interpolation</strong>.</p>
    <div class="vocab-section">
        <h3>Build Your Vocab</h3>
        <h4>Bilinear Interpolation</h4>
        <p>A mathematical method to estimate a value at a specific point based on the values of its four nearest neighbors. It allows us to sample features from 'in-between' pixels.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(17)">Continue</div>
</section>

<section id="section17">
    <div class="image-placeholder">
        <img src="images/3.jpg" alt="Illustration comparing jagged RoI pooling output to smooth RoIAlign result">
        <p class="image-caption">Quantization vs. precision: RoIAlign preserves the true contour.</p>
    </div>
    <p>By using RoIAlign, the features fed into the mask branch are perfectly aligned with the original image pixels. This allows the mask predictions to be sharp and accurate.</p>
    <div class="why-it-matters">
        <h3>Why It Matters</h3>
        <p>In high-stakes fields like medical imaging, a 1-pixel error in a tumor segmentation could mean the difference between healthy tissue and cancerous tissue. RoIAlign ensures that the neural network's 'vision' is not distorted by rounding errors.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(18)">Continue</div>
</section>

<section id="section18">
    <h2>Frequently Asked Questions</h2>
    <p>You might have some questions about how this fits together.</p>
    <div class="check-your-knowledge">
        <h3>Q: Does RoIAlign slow down the network?</h3>
        <div id="faq-answer-1" style="display:none;" class="animate-in">
            <strong>Answer:</strong> Slightly, yes. Calculating bilinear interpolation for four points per bin is computationally more expensive than simply rounding to the nearest integer (Pooling). However, the massive gain in mask accuracy is almost always worth the small cost in speed.
        </div>
        <button class="reveal-button" onclick="revealAnswer('faq-answer-1')">Reveal Answer</button>
    </div>
    <div class="continue-button" onclick="showNextSection(19)">Continue</div>
</section>

<section id="section19">
    <h2>Review and Reflect</h2>

    <p>Mask R-CNN turned instance segmentation from a complex, multi-stage pipeline into an elegant, end-to-end trainable system.</p>
    <ul>
        <li>We learned that it adds a <strong>Mask Branch</strong> to predict binary shapes for each class.</li>
        <li>We saw how the <strong>Multi-Task Loss</strong> combines classification, regression, and segmentation without confusion.</li>
        <li>We discovered that <strong>RoIAlign</strong> solves the quantization errors of RoI Pooling using bilinear interpolation.</li>
    </ul>
    <p>In the next and final lesson, we will leave the world of CNNs behind and look at the modern era: Vision Transformers and Foundation Models.</p>
</section>

<button id="markCompletedBtn" class="mark-completed-button" onclick="toggleCompleted()">✓ Mark as Completed</button>
</div>

<script>
let currentSection = 1;
const totalSections = 19;

updateProgress();
if (currentSection === totalSections) {
    const completedButton = document.getElementById('markCompletedBtn');
    if (completedButton) completedButton.classList.add('show');
}

function showNextSection(nextSectionId) {
    const nextSectionElement = document.getElementById(`section${nextSectionId}`);
    const currentButton = event && event.target;
    if (!nextSectionElement) return;
    if (currentButton && currentButton.classList.contains('continue-button')) {
        currentButton.style.display = 'none';
    }
    nextSectionElement.classList.add('visible');
    currentSection = nextSectionId;
    updateProgress();
    if (currentSection === totalSections) {
        const completedButton = document.getElementById('markCompletedBtn');
        if (completedButton) completedButton.classList.add('show');
    }
    setTimeout(() => { nextSectionElement.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 200);
}

function updateProgress() {
    const progressBar = document.getElementById('progressBar');
    const progress = (currentSection / totalSections) * 100;
    progressBar.style.width = `${progress}%`;
}

function revealAnswer(id) {
    const revealText = document.getElementById(id);
    const revealButton = event && event.target;
    if (revealText) {
        revealText.style.display = "block";
        revealText.classList.add('animate-in');
    }
    if (revealButton) {
        revealButton.style.display = "none";
    }
}

function selectChoice(element, isCorrect, explanation) {
    const choices = element.parentNode.querySelectorAll('.choice-option');
    choices.forEach(choice => {
        choice.classList.remove('selected', 'correct', 'incorrect');
        const existing = choice.querySelector('.choice-explanation');
        if (existing) existing.remove();
    });
    element.classList.add('selected');
    element.classList.add(isCorrect ? 'correct' : 'incorrect');
    const explanationDiv = document.createElement('div');
    explanationDiv.className = 'choice-explanation';
    explanationDiv.style.display = 'block';
    explanationDiv.innerHTML = `<strong>${isCorrect ? 'Correct!' : 'Not quite.'}</strong> ${explanation}`;
    element.appendChild(explanationDiv);
    
    // Only show continue button if answer is correct
    if (!isCorrect) return;
    
    // Auto-reveal continue button logic specific to this quiz section (section 8)
    const parentSection = element.closest('section');
    if (parentSection && parentSection.id === 'section8') {
        const continueButton = document.getElementById('continue-after-q1');
        if (continueButton && continueButton.style.display === 'none') {
            setTimeout(() => {
                continueButton.style.display = 'block';
                continueButton.classList.add('show-with-animation');
            }, 800);
        }
    }
}

document.addEventListener('keydown', function(e) {
    if (e.key === 'ArrowRight' || e.key === ' ') {
        const btn = document.querySelector(`#section${currentSection} .continue-button`);
        if (btn && btn.style.display !== 'none') {
            e.preventDefault();
            btn.click();
        }
    }
});

document.documentElement.style.scrollBehavior = 'smooth';

function toggleCompleted() {
    const button = document.getElementById('markCompletedBtn');
    if (!button) return;
    const isCompleted = button.classList.contains('completed');
    if (!isCompleted) {
        try {
            if (window.parent && window.parent.ProgressTracker) {
                // Tracking IDs updated for context
                let courseId = 'computer-vision';
                let pathId = 'instance-segmentation';
                let moduleId = 'cv-ch15-mask-rcnn';
                let lessonId = 'cv-ch15-l2-alignment-problem';
                
                if (window.parent.currentRoute) {
                    const route = window.parent.currentRoute;
                    if (route.courseId) courseId = route.courseId;
                    if (route.pathId) pathId = route.pathId;
                    if (route.moduleId) moduleId = route.moduleId;
                    if (route.lessonId) lessonId = route.lessonId;
                }
                const urlParams = new URLSearchParams(window.location.search);
                if (urlParams.get('course')) courseId = urlParams.get('course');
                if (urlParams.get('path')) pathId = urlParams.get('path');
                if (urlParams.get('module')) moduleId = urlParams.get('module');
                if (urlParams.get('lesson')) lessonId = urlParams.get('lesson');
                window.parent.ProgressTracker.markLessonCompleted(courseId, pathId, moduleId, lessonId);
            }
        } catch (error) {
            console.error('Error with ProgressTracker:', error);
        }
        button.classList.add('completed');
        button.innerHTML = '✅ Completed!';
        triggerCelebration();
        localStorage.setItem('lesson_cv-mask-rcnn-l2_completed', 'true');
    }
}

function triggerCelebration() {
    createConfetti();
    showSuccessMessage();
}

function createConfetti() {
    const confettiContainer = document.createElement('div');
    confettiContainer.className = 'confetti-container';
    document.body.appendChild(confettiContainer);
    const emojis = ['🎉', '🎊', '✨', '🌟', '🎈', '🏆', '👏', '🥳'];
    const colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7'];
    for (let i = 0; i < 40; i++) {
        setTimeout(() => {
            const confetti = document.createElement('div');
            confetti.className = 'confetti';
            if (Math.random() > 0.6) {
                confetti.textContent = emojis[Math.floor(Math.random() * emojis.length)];
            } else {
                confetti.innerHTML = '●';
                confetti.style.color = colors[Math.floor(Math.random() * colors.length)];
            }
            confetti.style.left = Math.random() * 100 + '%';
            confetti.style.animationDelay = Math.random() * 2 + 's';
            document.querySelector('.confetti-container').appendChild(confetti);
        }, i * 50);
    }
    setTimeout(() => { if (confettiContainer.parentNode) confettiContainer.parentNode.removeChild(confettiContainer); }, 5000);
}

function showSuccessMessage() {
    const successMessage = document.createElement('div');
    successMessage.className = 'success-message';
    successMessage.innerHTML = '🎉 Lesson Completed! Great Job! 🎉';
    document.body.appendChild(successMessage);
    setTimeout(() => { if (successMessage.parentNode) successMessage.parentNode.removeChild(successMessage); }, 2500);
}

window.addEventListener('load', function() {
    const button = document.getElementById('markCompletedBtn');
    if (!button) return;
    if (window.parent && window.parent.ProgressTracker) {
        // Same IDs as above for status check
        let courseId = 'computer-vision';
        let pathId = 'instance-segmentation';
        let moduleId = 'cv-ch15-mask-rcnn';
        let lessonId = 'cv-ch15-l2-alignment-problem';
        
        if (window.parent.currentRoute) {
            const route = window.parent.currentRoute;
            if (route.courseId) courseId = route.courseId;
            if (route.pathId) pathId = route.pathId;
            if (route.moduleId) moduleId = route.moduleId;
            if (route.lessonId) lessonId = route.lessonId;
        }
        const urlParams = new URLSearchParams(window.location.search);
        if (urlParams.get('course')) courseId = urlParams.get('course');
        if (urlParams.get('path')) pathId = urlParams.get('path');
        if (urlParams.get('module')) moduleId = urlParams.get('module');
        if (urlParams.get('lesson')) lessonId = urlParams.get('lesson');
        const progress = window.parent.ProgressTracker.getLessonProgress(courseId, pathId, moduleId, lessonId);
        if (progress.state === window.parent.ProgressTracker.STATES.COMPLETED) {
            button.classList.add('completed');
            button.innerHTML = '✅ Completed!';
            return;
        }
    }
    const isCompleted = localStorage.getItem('lesson_cv-mask-rcnn-l2_completed') === 'true';
    if (isCompleted) {
        button.classList.add('completed');
        button.innerHTML = '✅ Completed!';
    }
});
</script>
</body>
</html>