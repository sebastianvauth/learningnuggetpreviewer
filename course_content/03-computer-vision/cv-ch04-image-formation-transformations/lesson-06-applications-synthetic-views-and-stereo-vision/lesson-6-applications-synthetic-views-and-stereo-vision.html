<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<link rel="stylesheet" href="../../styles/lesson.css">
<style>
  .fov-tool-container {
    background: #ffffff;
    border: 1px solid #e2e8f0;
    border-radius: 12px;
    padding: 1.5rem;
    margin: 2rem 0;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
  }
  .fov-controls {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 1.5rem;
    margin-bottom: 1.5rem;
  }
  .fov-control-group {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
  }
  .fov-control-group label {
    display: flex;
    justify-content: space-between;
    font-weight: 600;
    color: #4a5568;
    font-size: 0.9rem;
  }
  .fov-control-group input[type="range"] {
    width: 100%;
    cursor: pointer;
  }
  .fov-result {
    margin-top: 1.5rem;
    padding-top: 1rem;
    border-top: 1px solid #e2e8f0;
    text-align: center;
  }
  .fov-result h4 {
    font-size: 0.85rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    color: #64748b;
    margin-bottom: 0.5rem;
  }
  .math-display {
    font-family: 'Inter', sans-serif;
    font-size: 1.25rem;
    font-weight: 700;
    color: #2d3748;
  }
  @media (max-width: 768px) {
    .fov-controls {
      grid-template-columns: 1fr;
      gap: 1rem;
    }
  }
</style>
<title>Applications: Synthetic Views & Stereo Vision</title>
<script>
window.MathJax = {
    tex: { inlineMath: [['\\(','\\)'], ['$', '$']] },
    options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
<div class="progress-container"><div class="progress-bar" id="progressBar"></div></div>
<div class="lesson-container">

<!-- Section 1: Intro -->
<section id="section1" class="visible">
    <div class="image-placeholder">
        <img src="images/1.jpg" alt="Comparison between a VR Headset (3D to 2D projection) and a DSLR Camera (capturing 2D images to reconstruct 3D space)." style="width: 100%; border-radius: 12px;">
    </div>
    <h1>Applications: Synthetic Views & Stereo Vision</h1>
    <h2>Introduction: The Two-Way Street</h2>
    <p>We have spent the last few lessons building a heavy mathematical toolbox: Homogeneous coordinates, intrinsic matrices (\(K\)), and extrinsic matrices (\([R|t]\)). You might be asking: "Why do I need to know linear algebra to take a picture?"</p>
    <div class="continue-button" onclick="showNextSection(2)">Continue</div>
</section>

<!-- Section 2: Directions -->
<section id="section2">
    <h2>Using the Math</h2>
    <p>The answer is that computer vision is a two-way street. We can use this math in two directions.</p>
    <div class="continue-button" onclick="showNextSection(3)">Continue</div>
</section>

<!-- Section 3: Forward/Backward Definitions -->
<section id="section3">
    <p>First, we can go <strong>Forward (3D \(\to\) 2D)</strong>: This is computer graphics. If we know where everything is in a virtual world, we can calculate exactly how it should look on a screen. This is called generating a <strong>Synthetic View</strong>.</p>
    <p>Second, we can go <strong>Backward (2D \(\to\) 3D)</strong>: This is traditional computer vision. We have a flat picture and want to figure out the shape and depth of the real world. This usually requires <strong>Stereo Vision</strong>.</p>
    <p>In this final lesson of the chapter, we will see how the Projection Matrix (\(P\)) powers both of these applications.</p>
    <div class="vocab-section">
        <h3>Build Your Vocab</h3>
        <h4>Synthetic View</h4>
        <p>An image generated by a computer from a 3D model, rather than captured by a physical camera. It uses the same projection mathematics (Matrix \(P\)) as a real camera.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(4)">Continue</div>
</section>

<!-- Section 4: Synthetic Views Concept -->
<section id="section4">
    <h2>Generating Synthetic Views</h2>
    <p>Imagine you are programming a self-driving car simulator. You have a 3D virtual city. You know the exact 3D coordinates (\(X, Y, Z\)) of every pedestrian and stop sign.</p>
    <div class="image-placeholder">
        <img src="images/2.jpg" alt="Diagram showing a 3D wireframe city being transformed through a projection matrix P into a 2D solid image on a monitor." style="width: 100%; border-radius: 12px;">
    </div>
    <p>To simulate what the car's camera sees, we simply apply the full projection matrix we learned in the previous lesson.</p>
    <div class="continue-button" onclick="showNextSection(5)">Continue</div>
</section>

<!-- Section 5: The Math -->
<section id="section5">
    <p>For every point \(\mathbf{p}_w\) in the virtual world, we calculate the pixel \(\mathbf{x}_s\):</p>
    <p>$$ \lambda \tilde{\mathbf{x}}_s = \mathbf{K}[\mathbf{R}|\mathbf{t}]\tilde{\mathbf{p}}_w $$</p>
    <p>Since we are the creators of this virtual world, we know \(\mathbf{K}\), \(\mathbf{R}\), \(\mathbf{t}\), and \(\mathbf{p}_w\). It's just a multiplication!</p>
    <p>However, there is one parameter we usually need to figure out based on design: the <strong>Focal Length</strong> (\(f\)).</p>
    <div class="continue-button" onclick="showNextSection(6)">Continue</div>
</section>

<!-- Section 6: FOV -->
<section id="section6">
    <p>In a physical camera, \(f\) is a lens property. In a virtual camera, we define it by choosing a <strong>Field of View (FOV)</strong>. If we want a wide-angle view (like a GoPro) or a zoomed-in view (like a sniper scope), we adjust the FOV.</p>
    <div class="vocab-section">
        <h3>Build Your Vocab</h3>
        <h4>Field of View (FOV)</h4>
        <p>The extent of the observable world that is seen at any given moment. In cameras, it is measured in degrees. A larger FOV means a wider angle of view.</p>
    </div>
    <div class="continue-button" onclick="showNextSection(7)">Continue</div>
</section>

<!-- Section 7: FOV Calculation -->
<section id="section7">
    <h2>Calculating Focal Length from FOV</h2>
    <p>How do we convert a desired FOV (in degrees) into a focal length (in pixels) for our matrix \(\mathbf{K}\)?</p>
    <p>We can use simple trigonometry. Imagine the camera looking at the image plane from the top down. If the image has width \(W\), the center is at \(W/2\). The triangle formed by the optical center, the image center, and the edge of the image has an angle of \(FOV/2\) and a base of \(f_x\).</p>
    <p>Using the definition of the tangent function:</p>
    <p>$$ \tan(\frac{FOV}{2}) = \frac{\text{Opposite}}{\text{Adjacent}} = \frac{W/2}{f_x} $$</p>
    <p>Solving for \(f_x\):</p>
    <p>$$ f_x = \frac{W/2}{\tan(FOV/2)} $$</p>
    <div class="continue-button" onclick="showNextSection(8)">Continue</div>
</section>

<!-- Section 8: Interactive Tool & Check Your Knowledge -->
<section id="section8">
    <p>Let's try this out. Use the calculator below to see how changing the FOV changes the required focal length.</p>
    <!-- START FOV CALCULATOR INTERACTIVE -->
<div class="fov-tool-container">
    <div class="fov-controls">
      <div class="fov-control-group">
        <label>
          Image Width (W)
          <span style="color:#667eea"><span id="val-width">1920</span> px</span>
        </label>
        <input type="range" id="input-width" min="640" max="4000" step="1" value="1920">
      </div>
      <div class="fov-control-group">
        <label>
          Field of View (FOV)
          <span style="color:#667eea"><span id="val-fov">90</span>¬∞</span>
        </label>
        <input type="range" id="input-fov" min="10" max="160" step="1" value="90">
      </div>
    </div>
  
    <div class="canvas-wrapper">
      <canvas id="fovCanvas"></canvas>
    </div>
  
    <div class="fov-result">
      <h4>Calculated Focal Length (\(f_x\))</h4>
      <div class="math-display" id="val-fx">960.00 px</div>
    </div>
  </div>
  
  <script>
  (function() {
    const canvas = document.getElementById('fovCanvas');
    const ctx = canvas.getContext('2d');
    
    const inputWidth = document.getElementById('input-width');
    const inputFov = document.getElementById('input-fov');
    
    const labelWidth = document.getElementById('val-width');
    const labelFov = document.getElementById('val-fov');
    const labelFx = document.getElementById('val-fx');
  
    // Handle High DPI displays
    function resizeCanvas() {
      const parent = canvas.parentElement;
      canvas.width = parent.clientWidth * window.devicePixelRatio;
      canvas.height = parent.clientHeight * window.devicePixelRatio;
      ctx.scale(window.devicePixelRatio, window.devicePixelRatio);
      canvas.style.width = parent.clientWidth + 'px';
      canvas.style.height = parent.clientHeight + 'px';
      draw();
    }
  
    function calculateFx(w, fovDeg) {
      const fovRad = fovDeg * (Math.PI / 180);
      return (w / 2) / Math.tan(fovRad / 2);
    }
  
    function draw() {
      // Get values
      const W = parseInt(inputWidth.value);
      const FOV = parseInt(inputFov.value);
      
      // Update labels
      labelWidth.textContent = W;
      labelFov.textContent = FOV;
      
      // Calculate Math
      const fx = calculateFx(W, FOV);
      labelFx.textContent = fx.toFixed(2) + " px";
  
      // --- VISUALIZATION LOGIC ---
      const width = canvas.width / window.devicePixelRatio;
      const height = canvas.height / window.devicePixelRatio;
      
      ctx.clearRect(0, 0, width, height);
  
      // Setup coordinates
      // We want to visualize the Top-Down view.
      // We fix the "Image Plane" visually near the top so it fits on screen.
      const visualPlaneY = 50; 
      const visualPlaneWidth = width * 0.6; // The image plane takes up 60% of canvas width
      const centerX = width / 2;
  
      // Calculate the Visual Focal Length (distance from plane to camera center)
      // Logic: tan(theta/2) = (VisualWidth/2) / visualDist
      // visualDist = (VisualWidth/2) / tan(theta/2)
      const fovRad = FOV * (Math.PI / 180);
      let visualDist = (visualPlaneWidth / 2) / Math.tan(fovRad / 2);
  
      // Clamp visual distance so camera center doesn't fly off screen too aggressively
      // If FOV is very narrow, visualDist gets huge. We might need to scale everything down.
      // Determine scale factor based on max height available
      const maxAvailableHeight = height - 100;
      let scale = 1;
      if (visualDist > maxAvailableHeight) {
        scale = maxAvailableHeight / visualDist;
      }
      
      // Apply scale to the visual elements
      const scaledDist = visualDist * scale;
      const scaledPlaneWidth = visualPlaneWidth * scale;
      
      const cameraY = visualPlaneY + scaledDist;
  
      // 1. Draw Frustum Fill (Light Purple)
      ctx.beginPath();
      ctx.moveTo(centerX, cameraY); // Camera Center
      ctx.lineTo(centerX - scaledPlaneWidth/2, visualPlaneY); // Top Left
      ctx.lineTo(centerX + scaledPlaneWidth/2, visualPlaneY); // Top Right
      ctx.closePath();
      ctx.fillStyle = 'rgba(102, 126, 234, 0.1)';
      ctx.fill();
  
      // 2. Draw Camera Center (Eye)
      ctx.beginPath();
      ctx.arc(centerX, cameraY, 6, 0, Math.PI * 2);
      ctx.fillStyle = '#2d3748';
      ctx.fill();
      ctx.fillStyle = '#4a5568';
      ctx.font = '12px sans-serif';
      ctx.fillText("Camera Center", centerX - 40, cameraY + 20);
  
      // 3. Draw Image Plane (Line)
      ctx.beginPath();
      ctx.moveTo(centerX - scaledPlaneWidth/2, visualPlaneY);
      ctx.lineTo(centerX + scaledPlaneWidth/2, visualPlaneY);
      ctx.lineWidth = 4;
      ctx.strokeStyle = '#667eea'; // Primary Purple
      ctx.stroke();
      
      // Label Image Plane
      ctx.fillStyle = '#667eea';
      ctx.font = 'bold 12px sans-serif';
      ctx.textAlign = 'center';
      ctx.fillText(`Image Width (W) = ${W}px`, centerX, visualPlaneY - 10);
  
      // 4. Draw Rays (Sides of Frustum)
      ctx.beginPath();
      ctx.moveTo(centerX, cameraY);
      ctx.lineTo(centerX - scaledPlaneWidth/2, visualPlaneY);
      ctx.moveTo(centerX, cameraY);
      ctx.lineTo(centerX + scaledPlaneWidth/2, visualPlaneY);
      ctx.lineWidth = 2;
      ctx.strokeStyle = '#cbd5e1';
      ctx.stroke();
  
      // 5. Draw Focal Length Arrow
      // Draw a dashed line down the center
      ctx.beginPath();
      ctx.setLineDash([5, 5]);
      ctx.moveTo(centerX, cameraY);
      ctx.lineTo(centerX, visualPlaneY);
      ctx.strokeStyle = '#a0aec0';
      ctx.stroke();
      ctx.setLineDash([]);
  
      // Draw label for f
      ctx.fillStyle = '#e53e3e'; // Red for emphasis
      ctx.font = 'bold 12px sans-serif';
      ctx.textAlign = 'right';
      ctx.fillText(`f = ${fx.toFixed(0)} px`, centerX - 10, visualPlaneY + scaledDist/2);
  
      // 6. Draw FOV Arc
      const arcRadius = Math.min(40, scaledDist/3);
      if (arcRadius > 10) {
          ctx.beginPath();
          ctx.arc(centerX, cameraY, arcRadius, 1.5 * Math.PI - fovRad/2, 1.5 * Math.PI + fovRad/2);
          ctx.strokeStyle = '#ed8936'; // Orange
          ctx.stroke();
          ctx.fillStyle = '#ed8936';
          ctx.textAlign = 'center';
          ctx.fillText(`${FOV}¬∞`, centerX, cameraY - arcRadius - 5);
      }
    }
  
    // Events
    inputWidth.addEventListener('input', draw);
    inputFov.addEventListener('input', draw);
    window.addEventListener('resize', resizeCanvas);
  
    // Use ResizeObserver to handle when the section becomes visible
    const resizeObserver = new ResizeObserver(() => {
      if (canvas.parentElement.clientWidth > 0) {
        resizeCanvas();
      }
    });
    resizeObserver.observe(canvas.parentElement);
  
    // Init
    resizeCanvas();
  })();
  </script>
  <!-- END FOV CALCULATOR INTERACTIVE -->
    
    <div class="check-your-knowledge">
        <h3>Stop and Think</h3>
        <h4>Based on the formula and the interactive tool, if you want to 'Zoom In' (make objects look bigger), do you need a smaller FOV or a larger FOV?</h4>
        <div id="cuy-fov-answer" style="display:none;" class="animate-in">
            <strong>Answer:</strong> You need a <strong>SMALLER FOV</strong> to zoom in. A smaller FOV means you are looking at a narrower slice of the world, which fills up the whole image, making individual objects appear larger. Mathematically, a smaller denominator in the formula results in a larger focal length (\(f_x\)).
        </div>
        <button class="reveal-button" onclick="revealAnswer('cuy-fov-answer')">Reveal Answer</button>
    </div>
    <div class="continue-button" onclick="showNextSection(9)">Continue</div>
</section>

<!-- Section 9: Stereo Vision Intro -->
<section id="section9">
    <h2>Stereo Vision: The Reverse Problem</h2>
    <p>Now let's flip the problem. Suppose we have a photo, and we want to know the 3D coordinates of a pixel. Can we do it?</p>
    <p>Not with a single camera. As we learned, projection squashes 3D space onto a 2D plane. We lose the depth information (\(\lambda\)). A pixel at \((100, 100)\) could represent a fly on the lens or a mountain miles away.</p>
    <p>To recover depth, we need <strong>Stereo Vision</strong>‚Äîtwo cameras looking at the same scene from different positions.</p>
    <div class="image-placeholder">
        <img src="images/3.jpg" alt="Diagram of Epipolar Geometry showing two cameras observing the same 3D point, with rays forming a triangle used for depth triangulation." style="width: 100%; border-radius: 12px;">
    </div>
    <div class="continue-button" onclick="showNextSection(10)">Continue</div>
</section>

<!-- Section 10: Triangulation & Math -->
<section id="section10">
    <p>If we identify that pixel \(\mathbf{x}_0\) in Camera 0 and pixel \(\mathbf{x}_1\) in Camera 1 correspond to the same physical point, we can cast rays from both cameras. The point where these rays intersect (Triangulate) is the 3D location.</p>
    <div class="vocab-section">
        <h3>Build Your Vocab</h3>
        <h4>Triangulation</h4>
        <p>The process of determining the location of a point in 3D space by measuring angles to it from known points at either end of a fixed baseline (like two cameras).</p>
    </div>
    <p>Mathematically, we are trying to solve for the depth \(\lambda\) that satisfies both projections:</p>
    <p>$$ \lambda_0 \tilde{\mathbf{x}}_0 = \mathbf{P}_0 \mathbf{p}_w $$</p>
    <p>$$ \lambda_1 \tilde{\mathbf{x}}_1 = \mathbf{P}_1 \mathbf{p}_w $$</p>
    <div class="continue-button" onclick="showNextSection(11)">Continue</div>
</section>

<!-- Section 11: Why it matters & Homography -->
<section id="section11">
    <div class="why-it-matters">
        <h3>Why It Matters</h3>
        <p>This is how biological vision works! Your eyes are two cameras separated by a baseline (your nose). Your brain triangulates the slight differences between what your left and right eyes see to give you depth perception. Self-driving cars and robot vacuums use the exact same math.</p>
    </div>
    <p>There is one special case where we <em>can</em> map pixels between cameras without knowing depth: <strong>Pure Rotation</strong>.</p>
    <p>If a camera rotates but does not move (translation \(\mathbf{t} = 0\)), the depth cancels out of the equations. The relationship between the two images becomes a <strong>Homography</strong> (\(H\)). This is how your phone stitches panoramas together!</p>
    <div class="continue-button" onclick="showNextSection(12)">Continue</div>
</section>

<!-- Section 12: Test Your Knowledge 1 -->
<section id="section12">
    <div class="test-your-knowledge">
        <h3>Test Your Knowledge</h3>
        <h4>Why can't you determine the exact 3D location of a point with just one standard image?</h4>
        <div class="multiple-choice">
            <div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Resolution affects detail, but even with infinite resolution, you would lack depth information.')">Because the resolution is too low.</div>
            <div class="choice-option" data-correct="true" onclick="selectChoice(this, true, 'Exactly. In the equation \\(\\lambda \\tilde{\\mathbf{x}} = \\mathbf{P} \\tilde{\\mathbf{p}}\\), the scalar \\(\\lambda\\) (depth) is unknown. Any point along the ray projects to the same pixel.')">Because depth information is lost during projection.</div>
            <div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Even if you know K perfectly, you still cannot recover the depth of a single point from one view.')">Because the intrinsic matrix K is unknown.</div>
        </div>
    </div>
    <div class="continue-button" onclick="showNextSection(13)">Continue</div>
</section>

<!-- Section 13: Test Your Knowledge 2 -->
<section id="section13">
    <div class="test-your-knowledge">
        <h3>Test Your Knowledge</h3>
        <h4>If I want a wider Field of View (like a GoPro) without changing the image resolution (W remains constant), how must the focal length change?</h4>
        <div class="multiple-choice">
            <div class="choice-option" data-correct="true" onclick="selectChoice(this, true, 'Correct! Looking at the formula \\(f_x = \\frac{W/2}{\\tan(FOV/2)}\\), if FOV increases, \\(\\tan(FOV/2)\\) increases. Since that term is in the denominator, \\(f_x\\) must decrease.')">It needs to get smaller.</div>
            <div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Incorrect. A larger focal length zooms in, which narrows the field of view.')">It needs to get larger.</div>
            <div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'No, focal length and FOV are inversely related for a fixed image size.')">It stays the same.</div>
        </div>
    </div>
    <div class="continue-button" id="continue-after-test-knowledge" onclick="showNextSection(14)" style="display: none;">Continue</div>
</section>

<!-- Section 14: Review & Video Games -->
<section id="section14">
    <div class="why-it-matters" style="background: linear-gradient(135deg, #fff8e1 0%, #fffbf0 100%); border-left-color: #ffd700; box-shadow: 0 10px 30px rgba(255, 215, 0, 0.1);">
        <h3 style="color: #d69e2e;">Common Question</h3>
        <h4>Why do video games use this math?</h4>
        <p>This <em>is</em> the graphics pipeline. Every single frame in games like Call of Duty or Minecraft is generated by taking millions of 3D points (\(p_w\)) and multiplying them by a Projection Matrix (\(\mathbf{P}\)) to figure out which pixel to light up on your monitor. This process is happening 60 times a second!</p>
    </div>
    
    <h2>Review and Reflect</h2>
    
    <p>You have now completed the chapter on Image Formation!</p>
    <p>We started with the concept of <strong>Homogeneous Coordinates</strong> to make our math linear. We explored <strong>2D Transformations</strong> to move images around. We built a virtual <strong>Pinhole Camera</strong> using <strong>Intrinsic</strong> and <strong>Extrinsic</strong> matrices. Finally, we saw how to use the full <strong>Projection Matrix</strong> to generate synthetic worlds or analyze the real one via <strong>Stereo Vision</strong>.</p>
    <p>In the next chapter, we will leave geometry behind and start looking at the signals <em>inside</em> the image using the Fourier Transform.</p>
</section>

<button id="markCompletedBtn" class="mark-completed-button" onclick="toggleCompleted()">‚úì Mark as Completed</button>
</div>

<script>
let currentSection = 1;
const totalSections = 14;

updateProgress();
if (currentSection === totalSections) {
    const completedButton = document.getElementById('markCompletedBtn');
    if (completedButton) completedButton.classList.add('show');
}

function showNextSection(nextSectionId) {
    const nextSectionElement = document.getElementById(`section${nextSectionId}`);
    const currentButton = event && event.target;
    if (!nextSectionElement) return;
    if (currentButton && currentButton.classList.contains('continue-button')) {
        currentButton.style.display = 'none';
    }
    nextSectionElement.classList.add('visible');
    currentSection = nextSectionId;
    updateProgress();
    if (currentSection === totalSections) {
        const completedButton = document.getElementById('markCompletedBtn');
        if (completedButton) completedButton.classList.add('show');
    }
    setTimeout(() => { nextSectionElement.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 200);
}

function updateProgress() {
    const progressBar = document.getElementById('progressBar');
    const progress = (currentSection / totalSections) * 100;
    progressBar.style.width = `${progress}%`;
}

function revealAnswer(id) {
    const revealText = document.getElementById(id);
    const revealButton = event && event.target;
    if (revealText) {
        revealText.style.display = "block";
        revealText.classList.add('animate-in');
    }
    if (revealButton) {
        revealButton.style.display = "none";
    }
}

function selectChoice(element, isCorrect, explanation) {
    const choices = element.parentNode.querySelectorAll('.choice-option');
    choices.forEach(choice => {
        choice.classList.remove('selected', 'correct', 'incorrect');
        const existing = choice.querySelector('.choice-explanation');
        if (existing) existing.remove();
    });
    element.classList.add('selected');
    element.classList.add(isCorrect ? 'correct' : 'incorrect');
    const explanationDiv = document.createElement('div');
    explanationDiv.className = 'choice-explanation';
    explanationDiv.style.display = 'block';
    explanationDiv.innerHTML = `<strong>${isCorrect ? 'Correct!' : 'Not quite.'}</strong> ${explanation}`;
    element.appendChild(explanationDiv);
    
    // Only show continue button if answer is correct
    if (!isCorrect) return;
    
    // Specifically for the last quiz in section 13 to reveal the continue button
    const parentSection = element.closest('section');
    if (parentSection && parentSection.id === 'section13') {
        const continueButton = document.getElementById('continue-after-test-knowledge');
        if (continueButton && continueButton.style.display === 'none') {
            setTimeout(() => {
                continueButton.style.display = 'block';
                continueButton.classList.add('show-with-animation');
            }, 800);
        }
    }
}

document.addEventListener('keydown', function(e) {
    if (e.key === 'ArrowRight' || e.key === ' ') {
        const btn = document.querySelector(`#section${currentSection} .continue-button`);
        if (btn && btn.style.display !== 'none') {
            e.preventDefault();
            btn.click();
        }
    }
});

document.documentElement.style.scrollBehavior = 'smooth';

function toggleCompleted() {
    const button = document.getElementById('markCompletedBtn');
    if (!button) return;
    const isCompleted = button.classList.contains('completed');
    if (!isCompleted) {
        try {
            if (window.parent && window.parent.ProgressTracker) {
                // Mock IDs for the CV curriculum
                let courseId = 'computer-vision';
                let pathId = 'image-formation';
                let moduleId = 'cv-ch02-formation';
                let lessonId = 'cv-ch02-l5-synthetic-stereo';
                
                if (window.parent.currentRoute) {
                    const route = window.parent.currentRoute;
                    if (route.courseId) courseId = route.courseId;
                    if (route.pathId) pathId = route.pathId;
                    if (route.moduleId) moduleId = route.moduleId;
                    if (route.lessonId) lessonId = route.lessonId;
                }
                const urlParams = new URLSearchParams(window.location.search);
                if (urlParams.get('course')) courseId = urlParams.get('course');
                if (urlParams.get('path')) pathId = urlParams.get('path');
                if (urlParams.get('module')) moduleId = urlParams.get('module');
                if (urlParams.get('lesson')) lessonId = urlParams.get('lesson');
                window.parent.ProgressTracker.markLessonCompleted(courseId, pathId, moduleId, lessonId);
            }
        } catch (error) {
            console.error('Error with ProgressTracker:', error);
        }
        button.classList.add('completed');
        button.innerHTML = '‚úÖ Completed!';
        triggerCelebration();
        localStorage.setItem('lesson_cv-ch02-l5_completed', 'true');
    }
}

function triggerCelebration() {
    createConfetti();
    showSuccessMessage();
}

function createConfetti() {
    const confettiContainer = document.createElement('div');
    confettiContainer.className = 'confetti-container';
    document.body.appendChild(confettiContainer);
    const emojis = ['üéâ', 'üéä', '‚ú®', 'üåü', 'üéà', 'üèÜ', 'üëè', 'ü•≥'];
    const colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7'];
    for (let i = 0; i < 40; i++) {
        setTimeout(() => {
            const confetti = document.createElement('div');
            confetti.className = 'confetti';
            if (Math.random() > 0.6) {
                confetti.textContent = emojis[Math.floor(Math.random() * emojis.length)];
            } else {
                confetti.innerHTML = '‚óè';
                confetti.style.color = colors[Math.floor(Math.random() * colors.length)];
            }
            confetti.style.left = Math.random() * 100 + '%';
            confetti.style.animationDelay = Math.random() * 2 + 's';
            document.querySelector('.confetti-container').appendChild(confetti);
        }, i * 50);
    }
    setTimeout(() => { if (confettiContainer.parentNode) confettiContainer.parentNode.removeChild(confettiContainer); }, 5000);
}

function showSuccessMessage() {
    const successMessage = document.createElement('div');
    successMessage.className = 'success-message';
    successMessage.innerHTML = 'üéâ Lesson Completed! Great Job! üéâ';
    document.body.appendChild(successMessage);
    setTimeout(() => { if (successMessage.parentNode) successMessage.parentNode.removeChild(successMessage); }, 2500);
}

window.addEventListener('load', function() {
    const button = document.getElementById('markCompletedBtn');
    if (!button) return;
    
    // Check local storage specific to this lesson ID
    const isCompleted = localStorage.getItem('lesson_cv-ch02-l5_completed') === 'true';
    if (isCompleted) {
        button.classList.add('completed');
        button.innerHTML = '‚úÖ Completed!';
    }
});
</script>
</body>
</html>