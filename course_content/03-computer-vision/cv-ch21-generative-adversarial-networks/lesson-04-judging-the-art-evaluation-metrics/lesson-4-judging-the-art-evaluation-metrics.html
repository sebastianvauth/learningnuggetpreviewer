<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<link rel="stylesheet" href="../../styles/lesson.css">
<title>Judging the Art (Evaluation Metrics)</title>
<script>
window.MathJax = {
tex: { inlineMath: [['\\(','\\)'], ['$', '$']] },
options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
<div class="progress-container"><div class="progress-bar" id="progressBar"></div></div>
<div class="lesson-container">
<!-- Section 1: Intro -->
<section id="section1" class="visible">
  <div class="image-placeholder">
    <img src="images/1.jpg" alt="Robot art critic comparing two wildly different AI generated paintings while holding a scorecard." loading="lazy">
  </div>
<h1>Judging the Art (Evaluation Metrics)</h1>

<h2>The Art Teacher's Dilemma</h2>
<p>Welcome back. In the previous lesson, we learned how to train our Generator and Discriminator. Ideally, they reach a balance where the Generator creates perfect fakes. But how do we <em>know</em> they are perfect?</p>
<div class="continue-button" onclick="showNextSection(2)">Continue</div>
</section>
<!-- Section 2: Missing Answer Key Intro -->
<section id="section2">
<h2>The Missing Answer Key</h2>
<p>If I give you a math test (Classification), I can easily grade it. You either got the right answer, or you didn't. There is a 'Ground Truth'.</p>
<div class="continue-button" onclick="showNextSection(3)">Continue</div>
</section>
<!-- Section 3 -->
<section id="section3">
<p>But if I ask you to paint a sunset, how do I grade it? There is no single correct pixel configuration for a sunset. There are infinite valid sunsets.</p>
<div class="continue-button" onclick="showNextSection(4)">Continue</div>
</section>
<!-- Section 4 -->
<section id="section4">
<p>This is the hardest part of Generative AI: <strong>Evaluation</strong>. We need a way to turn 'Does this look real?' into a number that a computer can track.</p>
<div class="continue-button" onclick="showNextSection(5)">Continue</div>
</section>
<!-- Section 5: Vocab -->
<section id="section5">
<p>While human evaluation is the ultimate test, it's too slow and expensive for training. We need automated metrics. The first major attempt at this was the <strong>Inception Score (IS)</strong>.</p>
<div class="vocab-section">
<h3>Build Your Vocab</h3>
<h4>Ground Truth</h4>
<p>In machine learning, 'Ground Truth' refers to the actual, correct target output (label) for a given input, used to verify the model's accuracy. Generative models often lack a specific ground truth for every generated sample.</p>
</div>
<div class="continue-button" onclick="showNextSection(6)">Continue</div>
</section>
<!-- Section 6: Inception Score Intro -->
<section id="section6">
<h2>The Inception Score (IS)</h2>
<p>The Inception Score relies on a pre-trained image classifier (specifically, the InceptionV3 network) to judge the art. It asks two fundamental questions to determine if a generator is doing a good job.</p>
<div class="continue-button" onclick="showNextSection(7)">Continue</div>
</section>
<!-- Section 7: Quality -->
<section id="section7">
<h3>1. Quality (Object-likeness)</h3>
<p>First, does the generated image look like a specific <em>thing</em>? If the generator makes a blurry mess, the classifier will be confused. It might say: "Maybe 20% dog, 20% cat, 60% toaster."</p>
<div class="continue-button" onclick="showNextSection(8)">Continue</div>
</section>
<!-- Section 8 -->
<section id="section8">
<p>We want the classifier to be confident. It should look at an image and say: "That is 99% a Siamese Cat."</p>
<p>In mathematical terms, for a generated image $x$, the conditional probability distribution $p(y|x)$ should have <strong>low entropy</strong> (low uncertainty).</p>
<div class="continue-button" onclick="showNextSection(9)">Continue</div>
</section>
<!-- Section 9: Diversity -->
<section id="section9">
<h3>2. Diversity</h3>
<p>Second, is the generator creative? If the model generates the exact same perfect cat photo 1,000 times, it has high quality but zero diversity.</p>
<div class="continue-button" onclick="showNextSection(10)">Continue</div>
</section>
<!-- Section 10: Marginal Distribution + Stop and Think -->
<section id="section10">
<p>We want the generator to explore all possible classes. Over the course of many images, the marginal distribution $p(y)$ should have <strong>high entropy</strong> (high uncertainty/uniform spread across classes).</p>
<div class="check-your-knowledge">
<h3>Stop and Think</h3>
<h4>Why do we want High Entropy for Diversity but Low Entropy for Quality?</h4>
<div id="st-is-answer" style="display:none;" class="animate-in">
<strong>Answer:</strong> Low Entropy for Quality means the model is sure about what a single image is (it's distinct). High Entropy for Diversity means the model is ensuring that, on average, it isn't favoring one class over others; it produces a bit of everything.
</div>
<button class="reveal-button" onclick="revealAnswer('st-is-answer')">Reveal Answer</button>
</div>
<div class="continue-button" onclick="showNextSection(11)">Continue</div>
</section>
<!-- Section 11: When Scores Lie Intro -->
<section id="section11">
<h2>When Scores Lie</h2>
<p>The Inception Score was a breakthrough, but it has a flaw. It focuses heavily on the final labels.</p>
<div class="continue-button" onclick="showNextSection(12)">Continue</div>
</section>
<!-- Section 12: Comic -->
<section id="section12">
<p>Because IS looks at class probabilities, it can be tricked. If a model memorizes one image per class and replays them, it gets a perfect score despite not learning the true distribution.</p>
<div class="image-placeholder">
  <img src="images/2.jpg" alt="Comic strip showing a generator fooling the Inception Score with repeated outputs until FID reveals the trick." loading="lazy">
  <p class="image-caption">IS can be duped by memorized samples—FID steps in like a detective with a magnifying glass.</p>
</div>
<div class="continue-button" onclick="showNextSection(13)">Continue</div>
</section>
<!-- Section 13: Fix -->
<section id="section13">
<p>To fix this, researchers introduced a metric that looks deeper than just the label: the <strong>Fréchet Inception Distance (FID)</strong>.</p>
<div class="continue-button" onclick="showNextSection(14)">Continue</div>
</section>
<!-- Section 14: FID Intro -->
<section id="section14">
<h2>Fréchet Inception Distance (FID)</h2>
<p>The FID is currently the gold standard for evaluating GANs. Instead of asking the classifier "What is this object?" (output layer), FID looks at the internal <strong>features</strong> (intermediate layers).</p>
<div class="continue-button" onclick="showNextSection(15)">Continue</div>
</section>
<!-- Section 15: Features -->
<section id="section15">
<p>It extracts high-level features (textures, shapes) from real images and generated images. It then assumes these features form a multi-dimensional Gaussian (bell curve) distribution.</p>
<div class="continue-button" onclick="showNextSection(16)">Continue</div>
</section>
<!-- Section 16: Interactive Plot -->
<section id="section16">
<p>It compares the statistics of the <strong>Real</strong> cloud of features against the <strong>Fake</strong> cloud of features.</p>
<!-- REPLACEMENT FOR SECTION 16 INTERACTIVE PLACEHOLDER -->
<div class="interactive-fid-container">
  <canvas id="fidCanvas"></canvas>
  
  <div class="fid-controls">
      <div class="slider-group">
          <label for="trainingSlider">Training Progress</label>
          <input type="range" id="trainingSlider" min="0" max="100" value="0">
          <div class="slider-labels">
              <span>Random Noise</span>
              <span>Perfect Replica</span>
          </div>
      </div>
      
      <div class="score-display">
          <div class="score-label">FID Score</div>
          <div class="score-value" id="fidScoreValue">45.2</div>
          <div class="score-subtext">Lower is Better</div>
      </div>
  </div>
</div>

<script>
(function() {
  const canvas = document.getElementById('fidCanvas');
  const ctx = canvas.getContext('2d');
  const slider = document.getElementById('trainingSlider');
  const scoreVal = document.getElementById('fidScoreValue');

  // Configuration
  const numPoints = 60;
  const focalLength = 400;
  let centerX, centerY;

  // Initialize canvas size
  function resizeCanvas() {
    const container = canvas.parentElement;
    const rect = container.getBoundingClientRect();
    const dpr = window.devicePixelRatio || 1;

    // Set display size
    canvas.style.width = '100%';
    canvas.style.height = '450px';

    // Set actual size in memory (scaled for DPI)
    const width = rect.width;
    const height = 450;
    canvas.width = width * dpr;
    canvas.height = height * dpr;

    // Scale context
    ctx.scale(dpr, dpr);

    // Update center points
    centerX = width / 2;
    centerY = height / 2;
  }

  resizeCanvas();
  window.addEventListener('resize', resizeCanvas);
  
  // Data structures
  let realCloud = [];
  let fakeCloud = [];
  let time = 0;

  // Initialize Points
  function initPoints() {
      // Real Data (Blue) - Centered at (100, 0, 0) in 3D space relative to canvas center
      for(let i=0; i<numPoints; i++) {
          realCloud.push({
              x: (Math.random() - 0.5) * 120 + 100, 
              y: (Math.random() - 0.5) * 120,
              z: (Math.random() - 0.5) * 120,
              speed: Math.random() * 0.02 + 0.01,
              offset: Math.random() * Math.PI * 2
          });
      }

      // Fake Data (Red) - Initially far away (-150, 50, -50)
      // We store 'base' positions, we will transform them based on slider
      for(let i=0; i<numPoints; i++) {
          fakeCloud.push({
              x: (Math.random() - 0.5) * 140, // Slightly more scattered initially
              y: (Math.random() - 0.5) * 140,
              z: (Math.random() - 0.5) * 140,
              speed: Math.random() * 0.02 + 0.01,
              offset: Math.random() * Math.PI * 2
          });
      }
  }

  // Project 3D to 2D
  function project(x, y, z) {
      const scale = focalLength / (focalLength + z);
      return {
          x: x * scale + centerX,
          y: y * scale + centerY,
          scale: scale
      };
  }

  function draw() {
      const width = canvas.width / (window.devicePixelRatio || 1);
      const height = canvas.height / (window.devicePixelRatio || 1);
      ctx.clearRect(0, 0, width, height);
      
      // Grid / Floor for perspective reference
      ctx.strokeStyle = "rgba(203, 213, 225, 0.4)";
      ctx.lineWidth = 1;
      ctx.beginPath();
      for(let i = -200; i <= 200; i+=40) {
          // Horizontal lines
          let p1 = project(-300, 100, i);
          let p2 = project(300, 100, i);
          ctx.moveTo(p1.x, p1.y);
          ctx.lineTo(p2.x, p2.y);
      }
      ctx.stroke();

      const progress = slider.value / 100; // 0 to 1
      
      // Calculate Clouds Centers (for arrow)
      // Real Cloud is static at x=100
      const realCenter3D = { x: 100, y: 0, z: 0 };
      
      // Fake cloud moves from x=-150 to x=100 based on progress
      const startX = -180;
      const targetX = 100;
      const currentFakeX = startX + (targetX - startX) * progress;
      
      // Fake cloud 'tightens' its variance as it trains (optional visual flair)
      const spreadFactor = 1 - (progress * 0.2); 

      // Update Score
      // Simple heuristic: Distance between centers + small random noise
      const distance = Math.abs(realCenter3D.x - currentFakeX);
      // Map distance to score: Max dist ~280 -> Score ~50. Min dist 0 -> Score ~2
      let calculatedFID = (distance / 6) + (2 * (1-progress));
      if(calculatedFID < 0) calculatedFID = 0;
      scoreVal.innerText = calculatedFID.toFixed(2);
      
      // 1. Prepare all points for sorting (Painter's Algorithm)
      let renderList = [];

      // Real Points (Blue)
      realCloud.forEach(p => {
          // Add subtle floating animation
          let py = p.y + Math.sin(time + p.offset) * 5;
          renderList.push({
              type: 'real',
              x3d: p.x, y3d: py, z3d: p.z
          });
      });

      // Fake Points (Red)
      fakeCloud.forEach(p => {
          let px = p.x * spreadFactor + currentFakeX;
          let py = p.y * spreadFactor + Math.sin(time + p.offset) * 5;
          let pz = p.z * spreadFactor;
          renderList.push({
              type: 'fake',
              x3d: px, y3d: py, z3d: pz
          });
      });

      // Sort by Z (depth) so far items draw first
      renderList.sort((a, b) => b.z3d - a.z3d);

      // 2. Draw Points
      renderList.forEach(p => {
          const proj = project(p.x3d, p.y3d, p.z3d);
          
          ctx.beginPath();
          ctx.arc(proj.x, proj.y, 6 * proj.scale, 0, Math.PI * 2);
          
          if (p.type === 'real') {
              ctx.fillStyle = `rgba(79, 172, 254, ${0.8 * proj.scale})`; // Blue
              ctx.shadowBlur = 0;
          } else {
              ctx.fillStyle = `rgba(255, 107, 107, ${0.8 * proj.scale})`; // Red
              // Add glow to red points
              ctx.shadowBlur = 10 * proj.scale;
              ctx.shadowColor = "rgba(255, 107, 107, 0.5)";
          }
          ctx.fill();
          ctx.shadowBlur = 0; // Reset
      });

      // 3. Draw Arrow and Labels (Overlay)
      const realCenter2D = project(realCenter3D.x, realCenter3D.y - 80, realCenter3D.z); // Slightly above
      const fakeCenter2D = project(currentFakeX, -80, 0); // Slightly above

      // Draw Line
      if (distance > 10) { // Only draw arrow if they aren't touching
          ctx.beginPath();
          ctx.moveTo(fakeCenter2D.x, fakeCenter2D.y);
          ctx.lineTo(realCenter2D.x, realCenter2D.y);
          ctx.strokeStyle = "#2d3748";
          ctx.lineWidth = 2;
          ctx.setLineDash([5, 5]);
          ctx.stroke();
          ctx.setLineDash([]);

          // Draw Label "Distance"
          const midX = (fakeCenter2D.x + realCenter2D.x) / 2;
          const midY = (fakeCenter2D.y + realCenter2D.y) / 2;
          
          ctx.fillStyle = "white";
          ctx.fillRect(midX - 30, midY - 12, 60, 24);
          ctx.strokeRect(midX - 30, midY - 12, 60, 24);
          
          ctx.fillStyle = "#2d3748";
          ctx.font = "bold 12px sans-serif";
          ctx.textAlign = "center";
          ctx.textBaseline = "middle";
          ctx.fillText("Distance", midX, midY);
      }

      // Cloud Labels
      ctx.font = "bold 14px sans-serif";
      
      // Real Label
      ctx.fillStyle = "#4facfe";
      ctx.fillText("Real Data", realCenter2D.x, realCenter2D.y - 20);
      
      // Generated Label
      ctx.fillStyle = "#ff6b6b";
      ctx.fillText("Generated", fakeCenter2D.x, fakeCenter2D.y - 20);

      time += 0.02;
      requestAnimationFrame(draw);
  }

  // Init
  initPoints();
  draw();

})();
</script>
<div class="continue-button" onclick="showNextSection(17)">Continue</div>
</section>
<!-- Section 17: Math explanation -->
<section id="section17">
<p>The math calculates the distance between these two distributions based on their <strong>Mean</strong> ($m$, the center of the cloud) and <strong>Covariance</strong> ($C$, the spread/shape of the cloud).</p>
<div class="continue-button" onclick="showNextSection(18)">Continue</div>
</section>
<!-- Section 18: Formula -->
<section id="section18">
<p>The formula looks intimidating, but the intuition is simple:</p>
<p>$$d^2 = ||m - m_w||_2^2 + \text{Tr}(C + C_w - 2(CC_w)^{1/2})$$</p>
<div class="continue-button" onclick="showNextSection(19)">Continue</div>
</section>
<!-- Section 19: Translation + Why it matters -->
<section id="section19">
<p>Let's translate that:</p>
<ol>
<li>$||m - m_w||_2^2$: The distance between the centers of the two clouds.</li>
<li>The rest: The difference in the shape and spread of the clouds.</li>
</ol>
<div class="why-it-matters">
<h3>Why It Matters</h3>
<p>FID correlates much better with human judgment than IS. If images look blurry or distorted to a human, the feature statistics drift away from reality, and the FID score goes up.</p>
</div>
<div class="continue-button" onclick="showNextSection(20)">Continue</div>
</section>
<!-- Section 20: Lower is Better + FAQ -->
<section id="section20">
<p>Crucially, unlike accuracy or the Inception Score, <strong>Lower is Better</strong> for FID. An FID of 0 means the distributions are identical.</p>
<div class="frequently-asked">
<h3>Frequently Asked</h3>
<h4>Does a low FID mean the images are perfect?</h4>
<div id="faq-fid-answer" style="display:none;" class="animate-in">
<strong>Answer:</strong> Not necessarily. A low FID means the generated images have similar statistics to the training set. However, the eye is still the best judge. FID is a great guide, but researchers always visually inspect the results too.
</div>
<button class="reveal-button" onclick="revealAnswer('faq-fid-answer')">Reveal Answer</button>
</div>

<div class="continue-button" onclick="showNextSection(21)">Continue</div>
</section>
<!-- Section 21: Review Intro -->
<section id="section21">
<h2>Review and Reflect</h2>
<p>Evaluation is the trickiest part of the Creative Universe. Since we lack an answer key, we rely on proxies.</p>
<div class="continue-button" onclick="showNextSection(22)">Continue</div>
</section>
<!-- Section 22: Summary -->
<section id="section22">
<ul>
<li><strong>Inception Score (IS)</strong> checks for <strong>Quality</strong> (distinct objects) and <strong>Diversity</strong> (variety of objects) using entropy.</li>
<li><strong>Fréchet Inception Distance (FID)</strong> measures the <strong>distance</strong> between the feature distributions of real and fake images. Lower is better.</li>
</ul>
<div class="continue-button" onclick="showNextSection(23)">Continue</div>
</section>
<!-- Section 23: Quiz -->
<section id="section23">
<div class="test-your-knowledge">
<h3>Test Your Knowledge</h3>
<h4>Which of the following scenarios represents the BEST performance for a GAN?</h4>
<div class="multiple-choice">
<div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Remember, for FID, lower is better (it\'s a distance). High FID means the images are far from reality.')">High Inception Score, High FID</div>
<div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'Low IS implies poor quality or poor diversity. We want IS to be high.')">Low Inception Score, Low FID</div>
<div class="choice-option" data-correct="true" onclick="selectChoice(this, true, 'Correct! We want high confidence/diversity (High IS) and a small distance between real and fake distributions (Low FID).')">High Inception Score, Low FID</div>
<div class="choice-option" data-correct="false" onclick="selectChoice(this, false, 'This is the worst-case scenario.')">Low Inception Score, High FID</div>
</div>
</div>
<div class="continue-button" id="continue-after-test-knowledge" onclick="showNextSection(24)" style="display: none;">Continue</div>
</section>
<!-- Section 24: Outro -->
<section id="section24">
<p>Now that we know how to judge our art, we are ready to expand our toolkit. In the next lesson, we'll look at advanced architectures that give us control over what we create, like turning sketches into photos.</p>
</section>
<button id="markCompletedBtn" class="mark-completed-button" onclick="toggleCompleted()">✓ Mark as Completed</button>
</div>
<script>
let currentSection = 1;
const totalSections = 24;

updateProgress();
if (currentSection === totalSections) {
const completedButton = document.getElementById('markCompletedBtn');
if (completedButton) completedButton.classList.add('show');
}

function showNextSection(nextSectionId) {
const nextSectionElement = document.getElementById(`section${nextSectionId}`);
const currentButton = event && event.target;
if (!nextSectionElement) return;
if (currentButton && currentButton.classList.contains('continue-button')) {
currentButton.style.display = 'none';
}
nextSectionElement.classList.add('visible');
currentSection = nextSectionId;
updateProgress();
if (currentSection === totalSections) {
const completedButton = document.getElementById('markCompletedBtn');
if (completedButton) completedButton.classList.add('show');
}
setTimeout(() => { nextSectionElement.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 200);
}

function updateProgress() {
const progressBar = document.getElementById('progressBar');
const progress = (currentSection / totalSections) * 100;
progressBar.style.width = `${progress}%`;
}

function revealAnswer(id) {
const revealText = document.getElementById(id);
const revealButton = event && event.target;
if (revealText) {
revealText.style.display = "block";
revealText.classList.add('animate-in');
}
if (revealButton) {
revealButton.style.display = "none";
}
}

function selectChoice(element, isCorrect, explanation) {
const choices = element.parentNode.querySelectorAll('.choice-option');
choices.forEach(choice => {
choice.classList.remove('selected', 'correct', 'incorrect');
const existing = choice.querySelector('.choice-explanation');
if (existing) existing.remove();
});
element.classList.add('selected');
element.classList.add(isCorrect ? 'correct' : 'incorrect');
const explanationDiv = document.createElement('div');
explanationDiv.className = 'choice-explanation';
explanationDiv.style.display = 'block';
explanationDiv.innerHTML = `<strong>${isCorrect ? 'Correct!' : 'Not quite.'}</strong> ${explanation}`;
element.appendChild(explanationDiv);
    
    // Only show continue button if answer is correct
    if (!isCorrect) return;
    
    // Auto-reveal continue button if correct or just after interaction depending on pedagogical preference.
// In this template, we reveal continue button after an attempt (correct or not) or specifically if correct.
// The previous template revealed it after interaction.
const parentSection = element.closest('section');
if (parentSection && parentSection.id === 'section23') {
const continueButton = document.getElementById('continue-after-test-knowledge');
if (continueButton && continueButton.style.display === 'none') {
setTimeout(() => {
continueButton.style.display = 'block';
continueButton.classList.add('show-with-animation');
}, 800);
}
}
}

document.addEventListener('keydown', function(e) {
if (e.key === 'ArrowRight' || e.key === ' ') {
const btn = document.querySelector(`#section${currentSection} .continue-button`);
if (btn && btn.style.display !== 'none') {
e.preventDefault();
btn.click();
}
}
});

document.documentElement.style.scrollBehavior = 'smooth';

function toggleCompleted() {
const button = document.getElementById('markCompletedBtn');
if (!button) return;
const isCompleted = button.classList.contains('completed');
if (!isCompleted) {
// Attempt LMS integration
try {
if (window.parent && window.parent.ProgressTracker) {
// These IDs should be updated based on the actual course structure if known
// Defaults maintained from template
let courseId = 'computer-vision';
let pathId = 'generative-adversarial-networks';
let moduleId = 'cv-ch21-m1-foundations';
let lessonId = 'cv-ch21-l2-judging-the-art';

if (window.parent.currentRoute) {
const route = window.parent.currentRoute;
if (route.courseId) courseId = route.courseId;
if (route.pathId) pathId = route.pathId;
if (route.moduleId) moduleId = route.moduleId;
// We assume this is lesson 2 based on context
if (route.lessonId) lessonId = route.lessonId;
}

// Also check URL params as backup
const urlParams = new URLSearchParams(window.location.search);
if (urlParams.get('course')) courseId = urlParams.get('course');
if (urlParams.get('path')) pathId = urlParams.get('path');
if (urlParams.get('module')) moduleId = urlParams.get('module');
if (urlParams.get('lesson')) lessonId = urlParams.get('lesson');

window.parent.ProgressTracker.markLessonCompleted(courseId, pathId, moduleId, lessonId);
}
} catch (error) {
console.error('Error with ProgressTracker:', error);
}

button.classList.add('completed');
button.innerHTML = '✅ Completed!';
triggerCelebration();
// Local storage key unique to this lesson
localStorage.setItem('lesson_cv-ch21-m1-l2_completed', 'true');
}
}

function triggerCelebration() {
createConfetti();
showSuccessMessage();
}

function createConfetti() {
const confettiContainer = document.createElement('div');
confettiContainer.className = 'confetti-container';
document.body.appendChild(confettiContainer);
const emojis = ['🎉', '🎊', '✨', '🌟', '🎈', '🏆', '👏', '🥳'];
const colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7'];

for (let i = 0; i < 40; i++) {
setTimeout(() => {
const confetti = document.createElement('div');
confetti.className = 'confetti';
if (Math.random() > 0.6) {
confetti.textContent = emojis[Math.floor(Math.random() * emojis.length)];
} else {
confetti.innerHTML = '●';
confetti.style.color = colors[Math.floor(Math.random() * colors.length)];
}
confetti.style.left = Math.random() * 100 + '%';
confetti.style.animationDelay = Math.random() * 2 + 's';
document.querySelector('.confetti-container').appendChild(confetti);
}, i * 50);
}

setTimeout(() => {
if (confettiContainer.parentNode) {
confettiContainer.parentNode.removeChild(confettiContainer);
}
}, 5000);
}

function showSuccessMessage() {
const successMessage = document.createElement('div');
successMessage.className = 'success-message';
successMessage.innerHTML = '🎉 Lesson Completed! Great Job! 🎉';
document.body.appendChild(successMessage);

setTimeout(() => {
if (successMessage.parentNode) {
successMessage.parentNode.removeChild(successMessage);
}
}, 2500);
}

// Check completion on load
window.addEventListener('load', function() {
const button = document.getElementById('markCompletedBtn');
if (!button) return;

// Check parent tracker
if (window.parent && window.parent.ProgressTracker) {
// Logic similar to toggleCompleted to fetch IDs
// ... (omitted for brevity, assumes default IDs or URL params work similarly)
}

// Check local storage
const isCompleted = localStorage.getItem('lesson_cv-ch21-m1-l2_completed') === 'true';
if (isCompleted) {
button.classList.add('completed');
button.innerHTML = '✅ Completed!';
}
});
</script>
</body>
</html>